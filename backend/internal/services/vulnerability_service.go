package services

import (
	"archive/tar"
	"bytes"
	"context"
	"encoding/json"
	"errors"
	"fmt"
	"io"
	"log/slog"
	"math"
	"net"
	"os"
	"strconv"
	"strings"
	"sync"
	"time"

	cerrdefs "github.com/containerd/errdefs"
	containertypes "github.com/docker/docker/api/types/container"
	imagetypes "github.com/docker/docker/api/types/image"
	mounttypes "github.com/docker/docker/api/types/mount"
	volumetypes "github.com/docker/docker/api/types/volume"
	"github.com/docker/docker/client"
	"github.com/docker/docker/pkg/stdcopy"
	"github.com/getarcaneapp/arcane/backend/internal/database"
	"github.com/getarcaneapp/arcane/backend/internal/models"
	"github.com/getarcaneapp/arcane/backend/internal/utils/pagination"
	"github.com/getarcaneapp/arcane/backend/internal/utils/timeouts"
	"github.com/getarcaneapp/arcane/backend/pkg/libarcane"
	"github.com/getarcaneapp/arcane/types/vulnerability"
	"gorm.io/gorm"
	"gorm.io/gorm/clause"
)

const (
	DefaultTrivyImage                  = "ghcr.io/aquasecurity/trivy:latest"
	trivyCacheVolumeName               = "arcane-trivy-cache"
	trivyCacheMountTarget              = "/root/.cache"
	trivyCacheSlotRootDir              = trivyCacheMountTarget + "/arcane-scan-slots"
	scanStaleTimeout                   = 30 * time.Minute
	defaultTrivyCPULimitCores          = 1.0
	defaultTrivyMemoryLimitMB    int64 = 0
	trivyNanoCPUsPerCore               = int64(1_000_000_000)
	trivyBytesPerMB                    = int64(1024 * 1024)
	trivyErrorExcerptSize              = int64(32 * 1024)
	defaultScanSaveRetryAttempts       = 3
	defaultScanSaveRetryDelay          = 200 * time.Millisecond
	defaultScanSaveRetryMaxDelay       = 2 * time.Second
	trivyOutputPathPrefix              = "/tmp/arcane-trivy-result-"
)

// VulnerabilityService handles vulnerability scanning of container images
type VulnerabilityService struct {
	db                  *database.DB
	dockerService       *DockerClientService
	eventService        *EventService
	settingsService     *SettingsService
	notificationService *NotificationService
	// scanLocks provides per-image locking to allow concurrent scans of different images
	// while preventing duplicate scans of the same image
	scanLocks sync.Map // map[string]*sync.Mutex
	// trivyScanSlots limits concurrent Trivy scans (manual + scheduled) and
	// provides deterministic slot IDs for shared-cache sharding.
	trivyScanSlots chan int
	trivyScanMu    sync.Mutex
	// scanPhases tracks live scan phases in-memory for in-progress scans.
	scanPhases sync.Map // map[string]vulnerability.ScanPhase
}

// getImageLock returns a mutex for the given image ID, creating one if needed
func (s *VulnerabilityService) getImageLock(imageID string) *sync.Mutex {
	lock, _ := s.scanLocks.LoadOrStore(imageID, &sync.Mutex{})
	return lock.(*sync.Mutex)
}

func (s *VulnerabilityService) setScanPhaseInternal(imageID string, phase vulnerability.ScanPhase) {
	if imageID == "" || phase == "" {
		return
	}
	s.scanPhases.Store(imageID, phase)
}

func (s *VulnerabilityService) clearScanPhaseInternal(imageID string) {
	if imageID == "" {
		return
	}
	s.scanPhases.Delete(imageID)
}

func (s *VulnerabilityService) getScanPhaseInternal(imageID string) vulnerability.ScanPhase {
	if imageID == "" {
		return ""
	}

	phase, ok := s.scanPhases.Load(imageID)
	if !ok {
		return ""
	}

	if typed, ok := phase.(vulnerability.ScanPhase); ok {
		return typed
	}

	if str, ok := phase.(string); ok {
		return vulnerability.ScanPhase(str)
	}

	return ""
}

func (s *VulnerabilityService) resolveScanPhaseInternal(imageID string, status vulnerability.ScanStatus) vulnerability.ScanPhase {
	if status != vulnerability.ScanStatusPending && status != vulnerability.ScanStatusScanning {
		return ""
	}

	if phase := s.getScanPhaseInternal(imageID); phase != "" {
		return phase
	}

	if status == vulnerability.ScanStatusPending {
		return vulnerability.ScanPhaseCreatingContainer
	}

	return vulnerability.ScanPhaseScanningImage
}

func (s *VulnerabilityService) applyScanPhaseToSummaryInternal(summary *vulnerability.ScanSummary) {
	if summary == nil {
		return
	}

	summary.ScanPhase = s.resolveScanPhaseInternal(summary.ImageID, summary.Status)
}

func (s *VulnerabilityService) applyScanPhaseToResultInternal(result *vulnerability.ScanResult) {
	if result == nil {
		return
	}

	result.ScanPhase = s.resolveScanPhaseInternal(result.ImageID, result.Status)
}

func (s *VulnerabilityService) acquireTrivyScanSlotInternal(ctx context.Context) (int, func(), error) {
	limit := s.getTrivyConcurrentScanContainersInternal()
	slotCh := s.getTrivyScanSlotChannelInternal(limit)
	if slotCh == nil {
		return 0, func() {}, nil
	}

	select {
	case slotID := <-slotCh:
		return slotID, func() { slotCh <- slotID }, nil
	case <-ctx.Done():
		return 0, nil, ctx.Err()
	}
}

func (s *VulnerabilityService) getTrivyConcurrentScanContainersInternal() int {
	if s.settingsService == nil {
		return 1
	}

	cfg := s.settingsService.GetSettingsConfig()
	if cfg == nil {
		return 1
	}

	limit := cfg.TrivyConcurrentScanContainers.AsInt()
	if limit < 1 {
		return 1
	}

	return limit
}

func (s *VulnerabilityService) getTrivyScanSlotChannelInternal(limit int) chan int {
	if limit < 1 {
		limit = 1
	}

	createSlots := func(size int) chan int {
		slots := make(chan int, size)
		for i := 0; i < size; i++ {
			slots <- i
		}
		return slots
	}

	s.trivyScanMu.Lock()
	defer s.trivyScanMu.Unlock()

	if s.trivyScanSlots == nil {
		s.trivyScanSlots = createSlots(limit)
		return s.trivyScanSlots
	}

	if cap(s.trivyScanSlots) == limit {
		return s.trivyScanSlots
	}

	// Apply capacity changes only when idle to avoid splitting tokens across channels.
	if len(s.trivyScanSlots) == cap(s.trivyScanSlots) {
		s.trivyScanSlots = createSlots(limit)
	}

	return s.trivyScanSlots
}

// NewVulnerabilityService creates a new VulnerabilityService instance
func NewVulnerabilityService(db *database.DB, dockerService *DockerClientService, eventService *EventService, settingsService *SettingsService, notificationService *NotificationService) *VulnerabilityService {
	return &VulnerabilityService{
		db:                  db,
		dockerService:       dockerService,
		eventService:        eventService,
		settingsService:     settingsService,
		notificationService: notificationService,
		trivyScanSlots:      nil,
	}
}

// ScanImage scans an image for vulnerabilities using Trivy
func (s *VulnerabilityService) ScanImage(ctx context.Context, envID string, imageID string, user models.User) (*vulnerability.ScanResult, error) {
	scanCtx := context.WithoutCancel(ctx)

	// Get Docker client to inspect the image
	dockerClient, err := s.dockerService.GetClient()
	if err != nil {
		return nil, fmt.Errorf("failed to connect to Docker: %w", err)
	}

	// Inspect the image to get details
	imageInspect, err := dockerClient.ImageInspect(scanCtx, imageID)
	if err != nil {
		return nil, fmt.Errorf("failed to inspect image: %w", err)
	}

	// Determine image name to scan
	imageName := imageID
	if len(imageInspect.RepoTags) > 0 {
		imageName = imageInspect.RepoTags[0]
	} else if len(imageInspect.RepoDigests) > 0 {
		imageName = imageInspect.RepoDigests[0]
	}

	slog.InfoContext(scanCtx,
		"vulnerability scan queued",
		"environmentId", envID,
		"imageId", imageID,
		"imageName", imageName,
	)
	s.setScanPhaseInternal(imageID, vulnerability.ScanPhaseCreatingContainer)

	// Create pending scan record
	pendingResult := &vulnerability.ScanResult{
		ImageID:   imageID,
		ImageName: imageName,
		ScanTime:  time.Now(),
		Status:    vulnerability.ScanStatusScanning,
	}
	s.applyScanPhaseToResultInternal(pendingResult)
	if saveErr := s.saveScanResultWithRetryInternal(scanCtx, pendingResult, defaultScanSaveRetryAttempts, defaultScanSaveRetryDelay); saveErr != nil {
		slog.WarnContext(scanCtx,
			"failed to save pending scan result",
			"error", saveErr,
			"imageId", imageID,
			"imageName", imageName,
		)
	} else {
		slog.DebugContext(scanCtx,
			"saved pending vulnerability scan record",
			"imageId", imageID,
			"imageName", imageName,
			"scanTime", pendingResult.ScanTime,
		)
	}

	go func(bgCtx context.Context, scanEnvID, imgID, imgName string, scanUser models.User) {
		s.scanImageInBackgroundInternal(bgCtx, scanEnvID, imgID, imgName, scanUser)
	}(scanCtx, envID, imageID, imageName, user)

	return pendingResult, nil
}

func (s *VulnerabilityService) markStaleScanIfNeeded(ctx context.Context, record *models.VulnerabilityScanRecord) bool {
	if record == nil {
		return false
	}
	if record.Status != models.ScanStatusScanning && record.Status != models.ScanStatusPending {
		return false
	}
	if time.Since(record.ScanTime) <= scanStaleTimeout {
		return false
	}

	errMsg := "Scan timed out or was interrupted. Please retry."
	record.Status = models.ScanStatusFailed
	record.Error = &errMsg
	record.Duration = time.Since(record.ScanTime).Milliseconds()
	s.clearScanPhaseInternal(record.ID)

	if s.db == nil {
		return true
	}

	if err := s.db.WithContext(ctx).
		Model(&models.VulnerabilityScanRecord{}).
		Where("id = ?", record.ID).
		Updates(map[string]any{
			"status":   record.Status,
			"error":    errMsg,
			"duration": record.Duration,
		}).Error; err != nil {
		slog.WarnContext(ctx, "failed to mark stale scan as failed", "error", err, "scan_id", record.ID)
		return false
	}

	return true
}

func (s *VulnerabilityService) scanImageInBackgroundInternal(ctx context.Context, envID string, imageID, imageName string, user models.User) {
	defer s.clearScanPhaseInternal(imageID)
	s.setScanPhaseInternal(imageID, vulnerability.ScanPhaseCreatingContainer)

	slog.DebugContext(ctx,
		"starting background vulnerability scan",
		"environmentId", envID,
		"imageId", imageID,
		"imageName", imageName,
	)

	trivyImage, err := s.ensureTrivyImageInternal(ctx)
	if err != nil {
		s.setScanPhaseInternal(imageID, vulnerability.ScanPhaseStoringResults)
		result := &vulnerability.ScanResult{
			ImageID:   imageID,
			ImageName: imageName,
			ScanTime:  time.Now(),
			Status:    vulnerability.ScanStatusFailed,
			Error:     fmt.Sprintf("Trivy scanner is not available: %s", err.Error()),
		}
		if saveErr := s.saveScanResultWithRetryInternal(ctx, result, defaultScanSaveRetryAttempts, defaultScanSaveRetryDelay); saveErr != nil {
			slog.WarnContext(ctx, "failed to save scan result", "error", saveErr)
		}
		slog.WarnContext(ctx,
			"background vulnerability scan failed before execution",
			"environmentId", envID,
			"imageId", imageID,
			"imageName", imageName,
			"error", result.Error,
		)
		return
	}

	startTime := time.Now()
	result, err := s.runTrivyScan(ctx, trivyImage, imageName, imageID)
	duration := time.Since(startTime).Milliseconds()

	if err != nil {
		s.setScanPhaseInternal(imageID, vulnerability.ScanPhaseStoringResults)
		failedResult := &vulnerability.ScanResult{
			ImageID:   imageID,
			ImageName: imageName,
			ScanTime:  time.Now(),
			Status:    vulnerability.ScanStatusFailed,
			Error:     err.Error(),
			Duration:  duration,
		}
		if saveErr := s.saveScanResultWithRetryInternal(ctx, failedResult, defaultScanSaveRetryAttempts, defaultScanSaveRetryDelay); saveErr != nil {
			slog.WarnContext(ctx, "failed to save failed scan result", "error", saveErr)
		}
		slog.WarnContext(ctx,
			"background vulnerability scan failed",
			"environmentId", envID,
			"imageId", imageID,
			"imageName", imageName,
			"durationMs", duration,
			"error", err,
		)
		s.logScanEvent(ctx, envID, imageID, imageName, user, false, err.Error())
		return
	}

	result.Duration = duration
	s.ensureSummary(result)
	s.setScanPhaseInternal(imageID, vulnerability.ScanPhaseStoringResults)
	if saveErr := s.saveScanResultWithRetryInternal(ctx, result, defaultScanSaveRetryAttempts, defaultScanSaveRetryDelay); saveErr != nil {
		slog.WarnContext(ctx, "failed to save scan result", "error", saveErr)
	}

	slog.InfoContext(ctx,
		"background vulnerability scan completed",
		"environmentId", envID,
		"imageId", imageID,
		"imageName", imageName,
		"durationMs", duration,
		"vulnerabilities", result.Summary.Total,
	)

	s.logScanEvent(ctx, envID, imageID, imageName, user, true, "")
}

// GetScanResult retrieves the most recent scan result for an image
func (s *VulnerabilityService) GetScanResult(ctx context.Context, imageID string) (*vulnerability.ScanResult, error) {
	if s.db == nil {
		return nil, nil
	}

	var record models.VulnerabilityScanRecord
	err := s.db.WithContext(ctx).Where("id = ?", imageID).First(&record).Error
	if err != nil {
		if errors.Is(err, gorm.ErrRecordNotFound) {
			return nil, nil
		}
		return nil, fmt.Errorf("failed to get scan result: %w", err)
	}

	s.markStaleScanIfNeeded(ctx, &record)

	return s.convertRecordToResult(&record)
}

// GetScanSummary retrieves just the summary for an image (for list views)
func (s *VulnerabilityService) GetScanSummary(ctx context.Context, imageID string) (*vulnerability.ScanSummary, error) {
	if s.db == nil {
		return nil, nil
	}

	var record models.VulnerabilityScanRecord
	err := s.db.WithContext(ctx).
		Select("id", "scan_time", "status", "critical_count", "high_count", "medium_count", "low_count", "unknown_count", "total_count", "error").
		Where("id = ?", imageID).
		First(&record).Error

	if err != nil {
		if errors.Is(err, gorm.ErrRecordNotFound) {
			return nil, nil
		}
		return nil, fmt.Errorf("failed to get scan summary: %w", err)
	}

	s.markStaleScanIfNeeded(ctx, &record)

	var errPtr *string
	if record.Error != nil {
		errPtr = record.Error
	}

	summary := &vulnerability.ScanSummary{
		ImageID:  record.ID,
		ScanTime: record.ScanTime,
		Status:   vulnerability.ScanStatus(record.Status),
		Summary: &vulnerability.SeveritySummary{
			Critical: record.CriticalCount,
			High:     record.HighCount,
			Medium:   record.MediumCount,
			Low:      record.LowCount,
			Unknown:  record.UnknownCount,
			Total:    record.TotalCount,
		},
		Error: stringPtrValueOrEmptyInternal(errPtr),
	}
	s.applyScanPhaseToSummaryInternal(summary)

	return summary, nil
}

// ListVulnerabilities returns a paginated, filtered list of vulnerabilities for an image.
func (s *VulnerabilityService) ListVulnerabilities(ctx context.Context, imageID string, params pagination.QueryParams) ([]vulnerability.Vulnerability, pagination.Response, error) {
	result, err := s.GetScanResult(ctx, imageID)
	if err != nil {
		return nil, pagination.Response{}, fmt.Errorf("failed to get scan result: %w", err)
	}
	if result == nil {
		limit := params.Limit
		if limit <= 0 {
			limit = 20
		}
		return []vulnerability.Vulnerability{}, pagination.Response{
			TotalPages:      1,
			TotalItems:      0,
			CurrentPage:     1,
			ItemsPerPage:    limit,
			GrandTotalItems: 0,
		}, nil
	}

	config := pagination.Config[vulnerability.Vulnerability]{
		SearchAccessors: []pagination.SearchAccessor[vulnerability.Vulnerability]{
			func(item vulnerability.Vulnerability) (string, error) { return item.VulnerabilityID, nil },
			func(item vulnerability.Vulnerability) (string, error) { return item.PkgName, nil },
			func(item vulnerability.Vulnerability) (string, error) { return item.InstalledVersion, nil },
			func(item vulnerability.Vulnerability) (string, error) { return item.FixedVersion, nil },
			func(item vulnerability.Vulnerability) (string, error) { return item.Title, nil },
		},
		SortBindings: []pagination.SortBinding[vulnerability.Vulnerability]{
			{
				Key: "vulnerabilityId",
				Fn: func(a, b vulnerability.Vulnerability) int {
					return strings.Compare(a.VulnerabilityID, b.VulnerabilityID)
				},
			},
			{
				Key: "pkgName",
				Fn:  func(a, b vulnerability.Vulnerability) int { return strings.Compare(a.PkgName, b.PkgName) },
			},
			{
				Key: "severity",
				Fn: func(a, b vulnerability.Vulnerability) int {
					return severityRankInternal(a.Severity) - severityRankInternal(b.Severity)
				},
			},
			{
				Key: "installedVersion",
				Fn: func(a, b vulnerability.Vulnerability) int {
					return strings.Compare(a.InstalledVersion, b.InstalledVersion)
				},
			},
			{
				Key: "fixedVersion",
				Fn:  func(a, b vulnerability.Vulnerability) int { return strings.Compare(a.FixedVersion, b.FixedVersion) },
			},
		},
		FilterAccessors: []pagination.FilterAccessor[vulnerability.Vulnerability]{
			{
				Key: "severity",
				Fn: func(item vulnerability.Vulnerability, value string) bool {
					return strings.EqualFold(string(item.Severity), value)
				},
			},
		},
	}

	filtered := pagination.SearchOrderAndPaginate(result.Vulnerabilities, params, config)
	response := pagination.BuildResponseFromFilterResult(filtered, params)

	return filtered.Items, response, nil
}

// GetEnvironmentSummary returns aggregated vulnerability counts across all images.
func (s *VulnerabilityService) GetEnvironmentSummary(ctx context.Context) (*vulnerability.EnvironmentVulnerabilitySummary, error) {
	if s.db != nil && s.dockerService != nil {
		if deleted, err := s.CleanupOrphanedScanRecords(ctx); err != nil {
			slog.WarnContext(ctx, "failed to cleanup orphaned vulnerability scan records", "error", err)
		} else if deleted > 0 {
			slog.DebugContext(ctx, "cleaned up orphaned vulnerability scan records", "deleted", deleted)
		}
	}

	summary := &vulnerability.EnvironmentVulnerabilitySummary{
		Summary: &vulnerability.SeveritySummary{},
	}

	if s.dockerService != nil {
		_, _, _, total, err := s.dockerService.GetAllImages(ctx)
		if err != nil {
			slog.WarnContext(ctx, "failed to list images for vulnerability summary", "error", err)
		} else {
			summary.TotalImages = total
		}
	}

	if s.db == nil {
		return summary, nil
	}

	type aggregate struct {
		Critical int `gorm:"column:critical"`
		High     int `gorm:"column:high"`
		Medium   int `gorm:"column:medium"`
		Low      int `gorm:"column:low"`
		Unknown  int `gorm:"column:unknown"`
		Total    int `gorm:"column:total"`
		Scanned  int `gorm:"column:scanned"`
	}

	var agg aggregate
	err := s.db.WithContext(ctx).
		Model(&models.VulnerabilityScanRecord{}).
		Select(
			"COALESCE(SUM(critical_count), 0) AS critical",
			"COALESCE(SUM(high_count), 0) AS high",
			"COALESCE(SUM(medium_count), 0) AS medium",
			"COALESCE(SUM(low_count), 0) AS low",
			"COALESCE(SUM(unknown_count), 0) AS unknown",
			"COALESCE(SUM(total_count), 0) AS total",
			"COUNT(*) AS scanned",
		).
		Where("status = ?", models.ScanStatusCompleted).
		Scan(&agg).Error
	if err != nil {
		return nil, fmt.Errorf("failed to aggregate vulnerability summary: %w", err)
	}

	summary.ScannedImages = agg.Scanned
	summary.Summary = &vulnerability.SeveritySummary{
		Critical: agg.Critical,
		High:     agg.High,
		Medium:   agg.Medium,
		Low:      agg.Low,
		Unknown:  agg.Unknown,
		Total:    agg.Total,
	}

	return summary, nil
}

// ListAllVulnerabilities returns a paginated list of vulnerabilities across all scanned images.
func (s *VulnerabilityService) ListAllVulnerabilities(ctx context.Context, envID string, params pagination.QueryParams) ([]vulnerability.VulnerabilityWithImage, pagination.Response, error) {
	if params.Limit == 0 {
		params.Limit = 20
	}

	if s.db == nil {
		return []vulnerability.VulnerabilityWithImage{}, pagination.Response{
			TotalPages:      1,
			TotalItems:      0,
			CurrentPage:     1,
			ItemsPerPage:    params.Limit,
			GrandTotalItems: 0,
		}, nil
	}

	var records []models.VulnerabilityScanRecord
	if err := s.db.WithContext(ctx).
		Select("id", "image_name", "vulnerabilities", "status", "total_count").
		Where("status = ?", models.ScanStatusCompleted).
		Where("total_count > 0").
		Find(&records).Error; err != nil {
		return nil, pagination.Response{}, fmt.Errorf("failed to list vulnerability scans: %w", err)
	}

	items := make([]vulnerability.VulnerabilityWithImage, 0)
	for _, record := range records {
		if len(record.Vulnerabilities) == 0 || record.Vulnerabilities[0] == "" {
			continue
		}

		var vulns []vulnerability.Vulnerability
		if err := json.Unmarshal([]byte(record.Vulnerabilities[0]), &vulns); err != nil {
			slog.WarnContext(ctx, "failed to unmarshal vulnerabilities", "error", err, "image_id", record.ID)
			continue
		}

		for _, vuln := range vulns {
			items = append(items, vulnerability.VulnerabilityWithImage{
				Vulnerability: vuln,
				ImageID:       record.ID,
				ImageName:     record.ImageName,
			})
		}
	}

	// Filter out ignored vulnerabilities
	items, err := s.filterIgnoredVulnerabilities(ctx, envID, items)
	if err != nil {
		slog.WarnContext(ctx, "failed to filter ignored vulnerabilities", "error", err)
	}

	config := pagination.Config[vulnerability.VulnerabilityWithImage]{
		SearchAccessors: []pagination.SearchAccessor[vulnerability.VulnerabilityWithImage]{
			func(item vulnerability.VulnerabilityWithImage) (string, error) { return item.VulnerabilityID, nil },
			func(item vulnerability.VulnerabilityWithImage) (string, error) { return item.PkgName, nil },
			func(item vulnerability.VulnerabilityWithImage) (string, error) { return item.InstalledVersion, nil },
			func(item vulnerability.VulnerabilityWithImage) (string, error) { return item.FixedVersion, nil },
			func(item vulnerability.VulnerabilityWithImage) (string, error) { return item.Title, nil },
			func(item vulnerability.VulnerabilityWithImage) (string, error) { return item.ImageName, nil },
			func(item vulnerability.VulnerabilityWithImage) (string, error) { return item.ImageID, nil },
		},
		SortBindings: []pagination.SortBinding[vulnerability.VulnerabilityWithImage]{
			{
				Key: "vulnerabilityId",
				Fn: func(a, b vulnerability.VulnerabilityWithImage) int {
					return strings.Compare(a.VulnerabilityID, b.VulnerabilityID)
				},
			},
			{
				Key: "pkgName",
				Fn:  func(a, b vulnerability.VulnerabilityWithImage) int { return strings.Compare(a.PkgName, b.PkgName) },
			},
			{
				Key: "severity",
				Fn: func(a, b vulnerability.VulnerabilityWithImage) int {
					return severityRankInternal(a.Severity) - severityRankInternal(b.Severity)
				},
			},
			{
				Key: "installedVersion",
				Fn: func(a, b vulnerability.VulnerabilityWithImage) int {
					return strings.Compare(a.InstalledVersion, b.InstalledVersion)
				},
			},
			{
				Key: "fixedVersion",
				Fn: func(a, b vulnerability.VulnerabilityWithImage) int {
					return strings.Compare(a.FixedVersion, b.FixedVersion)
				},
			},
			{
				Key: "imageName",
				Fn:  func(a, b vulnerability.VulnerabilityWithImage) int { return strings.Compare(a.ImageName, b.ImageName) },
			},
		},
		FilterAccessors: []pagination.FilterAccessor[vulnerability.VulnerabilityWithImage]{
			{
				Key: "severity",
				Fn: func(item vulnerability.VulnerabilityWithImage, value string) bool {
					return strings.EqualFold(string(item.Severity), value)
				},
			},
			{
				Key: "imageName",
				Fn: func(item vulnerability.VulnerabilityWithImage, value string) bool {
					itemLower := strings.ToLower(item.ImageName)
					for part := range strings.SplitSeq(value, ",") {
						if part = strings.TrimSpace(part); part != "" && strings.Contains(itemLower, strings.ToLower(part)) {
							return true
						}
					}
					return false
				},
			},
		},
	}

	filtered := pagination.SearchOrderAndPaginate(items, params, config)
	response := pagination.BuildResponseFromFilterResult(filtered, params)

	return filtered.Items, response, nil
}

func severityRankInternal(severity vulnerability.Severity) int {
	switch severity {
	case vulnerability.SeverityCritical:
		return 4
	case vulnerability.SeverityHigh:
		return 3
	case vulnerability.SeverityMedium:
		return 2
	case vulnerability.SeverityLow:
		return 1
	case vulnerability.SeverityUnknown:
		return 0
	default:
		return 0
	}
}

// GetScanSummariesByImageIDs retrieves scan summaries for multiple images
func (s *VulnerabilityService) GetScanSummariesByImageIDs(ctx context.Context, imageIDs []string) (map[string]*vulnerability.ScanSummary, error) {
	if s.db == nil || len(imageIDs) == 0 {
		return make(map[string]*vulnerability.ScanSummary), nil
	}

	var records []models.VulnerabilityScanRecord
	err := s.db.WithContext(ctx).
		Select("id", "scan_time", "status", "critical_count", "high_count", "medium_count", "low_count", "unknown_count", "total_count", "error").
		Where("id IN ?", imageIDs).
		Find(&records).Error

	if err != nil {
		return nil, fmt.Errorf("failed to get scan summaries: %w", err)
	}

	result := make(map[string]*vulnerability.ScanSummary, len(records))
	for _, record := range records {
		s.markStaleScanIfNeeded(ctx, &record)
		var errStr string
		if record.Error != nil {
			errStr = *record.Error
		}

		result[record.ID] = &vulnerability.ScanSummary{
			ImageID:  record.ID,
			ScanTime: record.ScanTime,
			Status:   vulnerability.ScanStatus(record.Status),
			Summary: &vulnerability.SeveritySummary{
				Critical: record.CriticalCount,
				High:     record.HighCount,
				Medium:   record.MediumCount,
				Low:      record.LowCount,
				Unknown:  record.UnknownCount,
				Total:    record.TotalCount,
			},
			Error: errStr,
		}
		s.applyScanPhaseToSummaryInternal(result[record.ID])
	}

	return result, nil
}

type scheduledScanNotificationSummary struct {
	totalFixable      int
	imagesWithFixable int
	severityCounts    map[string]int
	sampleCVEs        []string
	seenCVEs          map[string]struct{}
}

func newScheduledScanNotificationSummary() *scheduledScanNotificationSummary {
	return &scheduledScanNotificationSummary{
		severityCounts: map[string]int{
			"CRITICAL": 0,
			"HIGH":     0,
			"MEDIUM":   0,
			"LOW":      0,
			"UNKNOWN":  0,
		},
		sampleCVEs: make([]string, 0, 5),
		seenCVEs:   make(map[string]struct{}),
	}
}

func scheduledScanImageTargetInternal(img imagetypes.Summary) (imageID, imageName string, shouldScan bool) {
	imageID = img.ID
	imageName = imageID
	if len(img.RepoTags) > 0 {
		imageName = img.RepoTags[0]
	} else if len(img.RepoDigests) > 0 {
		imageName = img.RepoDigests[0]
	}

	// Skip intermediate / dangling images with no usable name.
	if imageName == "<none>:<none>" || imageName == imageID {
		return imageID, imageName, false
	}

	return imageID, imageName, true
}

func (s *VulnerabilityService) runScheduledImageScanInternal(
	ctx context.Context,
	containerID, imageName, imageID, scannerVersion string,
) (*vulnerability.ScanResult, int64, error) {
	startTime := time.Now()
	_, releaseSlot, slotErr := s.acquireTrivyScanSlotInternal(ctx)
	if slotErr != nil {
		return nil, 0, slotErr
	}

	var result *vulnerability.ScanResult
	var scanErr error
	func() {
		defer releaseSlot()
		result, scanErr = s.execTrivyScanInContainer(ctx, containerID, imageName, imageID, scannerVersion)
	}()

	return result, time.Since(startTime).Milliseconds(), scanErr
}

func (s *VulnerabilityService) saveScheduledFailedScanInternal(
	ctx context.Context,
	envID, imageID, imageName string,
	user models.User,
	duration int64,
	scanErr error,
) {
	failedResult := &vulnerability.ScanResult{
		ImageID:   imageID,
		ImageName: imageName,
		ScanTime:  time.Now(),
		Status:    vulnerability.ScanStatusFailed,
		Error:     scanErr.Error(),
		Duration:  duration,
	}
	if saveErr := s.saveScanResultWithRetryInternal(ctx, failedResult, defaultScanSaveRetryAttempts, defaultScanSaveRetryDelay); saveErr != nil {
		slog.WarnContext(ctx, "failed to save failed scan result", "error", saveErr)
	}
	s.logScheduledScanEvent(ctx, envID, imageID, imageName, user, false, scanErr.Error())
}

func (s *VulnerabilityService) saveScheduledSuccessfulScanInternal(
	ctx context.Context,
	envID, imageID, imageName string,
	user models.User,
	result *vulnerability.ScanResult,
	duration int64,
) {
	result.Duration = duration
	s.ensureSummary(result)
	if saveErr := s.saveScanResultWithRetryInternal(ctx, result, defaultScanSaveRetryAttempts, defaultScanSaveRetryDelay); saveErr != nil {
		slog.WarnContext(ctx, "failed to save scan result", "error", saveErr)
	}
	s.logScheduledScanEvent(ctx, envID, imageID, imageName, user, true, "")
}

func (s *VulnerabilityService) collectScheduledFixableSummaryInternal(
	ctx context.Context,
	result *vulnerability.ScanResult,
	summary *scheduledScanNotificationSummary,
) {
	fixableVulns := s.fixedVulnerabilitiesForNotifications(ctx, result)
	if len(fixableVulns) == 0 {
		return
	}

	summary.imagesWithFixable++
	for i := range fixableVulns {
		v := fixableVulns[i]
		summary.totalFixable++

		sev := strings.ToUpper(strings.TrimSpace(string(v.Severity)))
		if _, ok := summary.severityCounts[sev]; !ok {
			sev = "UNKNOWN"
		}
		summary.severityCounts[sev]++

		cveID := strings.TrimSpace(v.VulnerabilityID)
		if cveID == "" {
			continue
		}
		if _, alreadyAdded := summary.seenCVEs[cveID]; alreadyAdded {
			continue
		}
		summary.seenCVEs[cveID] = struct{}{}
		if len(summary.sampleCVEs) < 5 {
			summary.sampleCVEs = append(summary.sampleCVEs, cveID)
		}
	}
}

func (s *VulnerabilityService) sendScheduledVulnerabilitySummaryInternal(
	ctx context.Context,
	scanned int,
	summary *scheduledScanNotificationSummary,
) {
	if summary.totalFixable == 0 || s.notificationService == nil {
		return
	}

	summaryDate := time.Now().UTC().Format("2006-01-02")
	payload := VulnerabilityNotificationPayload{
		CVEID:        fmt.Sprintf("Daily Summary - %s", summaryDate),
		Severity:     fmt.Sprintf("Critical:%d High:%d Medium:%d Low:%d Unknown:%d", summary.severityCounts["CRITICAL"], summary.severityCounts["HIGH"], summary.severityCounts["MEDIUM"], summary.severityCounts["LOW"], summary.severityCounts["UNKNOWN"]),
		ImageName:    fmt.Sprintf("%d image(s) scanned, %d with fixable vulnerabilities", scanned, summary.imagesWithFixable),
		FixedVersion: fmt.Sprintf("%d fixable vulnerability record(s)", summary.totalFixable),
	}
	if len(summary.sampleCVEs) > 0 {
		payload.PkgName = strings.Join(summary.sampleCVEs, ", ")
	}

	if err := s.notificationService.SendVulnerabilityNotification(ctx, payload); err != nil {
		slog.WarnContext(ctx, "failed to send daily vulnerability summary notification", "error", err)
	}
}

// ScanAllImages scans all Docker images for vulnerabilities. It is intended
// for use by the scheduled vulnerability scan job. A single long-running Trivy
// container is created and reused for every image via docker exec, which avoids
// the overhead of creating/destroying a container per scan. The caller-supplied
// user is recorded in the event log.
func (s *VulnerabilityService) ScanAllImages(ctx context.Context, envID string, user models.User) (scanned, failed int, err error) {
	dockerClient, err := s.dockerService.GetClient()
	if err != nil {
		return 0, 0, fmt.Errorf("failed to connect to Docker: %w", err)
	}

	images, err := dockerClient.ImageList(ctx, imagetypes.ListOptions{})
	if err != nil {
		return 0, 0, fmt.Errorf("failed to list images: %w", err)
	}

	containerID, cleanup, err := s.setupTrivyBatchContainer(ctx)
	if err != nil {
		return 0, 0, err
	}
	defer cleanup()

	scannerVersion := s.GetTrivyVersion(ctx)
	notificationSummary := newScheduledScanNotificationSummary()

	for _, img := range images {
		if ctx.Err() != nil {
			return scanned, failed, ctx.Err()
		}

		switch s.scanSingleImage(ctx, containerID, img, scannerVersion, envID, user, notificationSummary) {
		case scanStatusSuccess:
			scanned++
		case scanStatusFailed:
			failed++
		case scanStatusSkipped:
			// no-op
		}
	}

	s.sendScheduledVulnerabilitySummaryInternal(ctx, scanned, notificationSummary)

	return scanned, failed, nil
}

type scanResultStatus int

const (
	scanStatusSkipped scanResultStatus = iota
	scanStatusSuccess
	scanStatusFailed
)

func (s *VulnerabilityService) setupTrivyBatchContainer(ctx context.Context) (string, func(), error) {
	dockerClient, err := s.dockerService.GetClient()
	if err != nil {
		return "", nil, fmt.Errorf("failed to connect to Docker: %w", err)
	}

	trivyImage, err := s.ensureTrivyImageInternal(ctx)
	if err != nil {
		return "", nil, fmt.Errorf("trivy scanner not available: %w", err)
	}

	cacheVolume, err := s.ensureTrivyCacheVolumeInternal(ctx)
	if err != nil {
		return "", nil, fmt.Errorf("failed to ensure trivy cache volume: %w", err)
	}

	containerID, err := s.createBatchTrivyContainer(ctx, trivyImage, cacheVolume)
	if err != nil {
		return "", nil, fmt.Errorf("failed to create batch trivy container: %w", err)
	}

	cleanup := func() {
		removeDockerContainerInternal(ctx, dockerClient, containerID, "failed to remove batch trivy container")
	}

	return containerID, cleanup, nil
}

func (s *VulnerabilityService) scanSingleImage(
	ctx context.Context,
	containerID string,
	img imagetypes.Summary,
	scannerVersion, envID string,
	user models.User,
	notificationSummary *scheduledScanNotificationSummary,
) scanResultStatus {
	imageID, imageName, shouldScan := scheduledScanImageTargetInternal(img)
	if !shouldScan {
		return scanStatusSkipped
	}

	slog.InfoContext(ctx, "scheduled vulnerability scan: scanning image", "image", imageName, "imageId", imageID)

	result, duration, scanErr := s.runScheduledImageScanInternal(ctx, containerID, imageName, imageID, scannerVersion)
	if scanErr != nil {
		s.saveScheduledFailedScanInternal(ctx, envID, imageID, imageName, user, duration, scanErr)
		return scanStatusFailed
	}

	s.saveScheduledSuccessfulScanInternal(ctx, envID, imageID, imageName, user, result, duration)
	s.collectScheduledFixableSummaryInternal(ctx, result, notificationSummary)
	return scanStatusSuccess
}

// createBatchTrivyContainer creates a long-running Trivy container that stays
// alive so we can exec individual scan commands into it. This avoids the
// overhead of creating/starting/removing a container for every image.
func (s *VulnerabilityService) createBatchTrivyContainer(ctx context.Context, trivyImage, cacheVolume string) (string, error) {
	dockerClient, err := s.dockerService.GetClient()
	if err != nil {
		return "", fmt.Errorf("failed to connect to Docker: %w", err)
	}

	config := &containertypes.Config{
		Image:      trivyImage,
		Entrypoint: []string{"sh", "-c", "trap 'exit 0' TERM; while :; do sleep 1; done"},
		Labels: map[string]string{
			libarcane.InternalResourceLabel: "true",
		},
	}

	hostConfig := &containertypes.HostConfig{
		Mounts: []mounttypes.Mount{
			{
				Type:   mounttypes.TypeBind,
				Source: "/var/run/docker.sock",
				Target: "/var/run/docker.sock",
			},
			{
				Type:   mounttypes.TypeVolume,
				Source: cacheVolume,
				Target: trivyCacheMountTarget,
			},
		},
	}

	resources, cpuSet, applyLimits := s.getTrivyContainerResourceOptionsInternal(ctx, dockerClient)
	applyTrivyContainerResourcesInternal(hostConfig, resources, cpuSet, applyLimits)

	containerID, err := s.createAndStartTrivyContainerInternal(ctx, dockerClient, "batch", config, hostConfig)
	if err != nil {
		return "", err
	}

	slog.InfoContext(ctx, "batch trivy container started", "containerId", containerID)

	return containerID, nil
}

// execTrivyScanInContainer runs a trivy scan for a single image inside an
// already-running container via docker exec.
func (s *VulnerabilityService) execTrivyScanInContainer(ctx context.Context, containerID, imageName, imageID, scannerVersion string) (*vulnerability.ScanResult, error) {
	dockerClient, err := s.dockerService.GetClient()
	if err != nil {
		return nil, fmt.Errorf("failed to connect to Docker: %w", err)
	}

	stdoutFile, err := createTrivyLogTempFileInternal("trivy-exec-stdout-*")
	if err != nil {
		return nil, fmt.Errorf("failed to create trivy exec stdout temp file: %w", err)
	}

	stderrFile, err := createTrivyLogTempFileInternal("trivy-exec-stderr-*")
	if err != nil {
		cleanupTrivyLogTempFilesInternal(ctx, stdoutFile)
		return nil, fmt.Errorf("failed to create trivy exec stderr temp file: %w", err)
	}
	defer cleanupTrivyLogTempFilesInternal(ctx, stdoutFile, stderrFile)

	trivyTimeout := s.getTrivyScanTimeoutArg()
	outputPath := newTrivyOutputPathInternal()
	defer cleanupTrivyOutputFileInContainerInternal(ctx, dockerClient, containerID, outputPath)

	execCfg := containertypes.ExecOptions{
		Cmd:          []string{"trivy", "image", "--format", "json", "--quiet", "--output", outputPath, "--timeout", trivyTimeout, imageName},
		AttachStdout: true,
		AttachStderr: true,
	}

	execResp, err := dockerClient.ContainerExecCreate(ctx, containerID, execCfg)
	if err != nil {
		return nil, fmt.Errorf("failed to create exec: %w", err)
	}

	attachResp, err := dockerClient.ContainerExecAttach(ctx, execResp.ID, containertypes.ExecAttachOptions{})
	if err != nil {
		return nil, fmt.Errorf("failed to attach to exec: %w", err)
	}
	defer attachResp.Close()

	logDone := startDockerLogCopyInternal(attachResp.Reader, stdoutFile, stderrFile)
	if err := waitForDockerLogCopyInternal(logDone); err != nil {
		return nil, fmt.Errorf("failed to read exec output: %w", err)
	}

	// Check exit code
	execInspect, err := dockerClient.ContainerExecInspect(ctx, execResp.ID)
	if err != nil {
		return nil, fmt.Errorf("failed to inspect exec: %w", err)
	}

	if execInspect.ExitCode != 0 {
		errMsg := readTempFileExcerptInternal(stderrFile, trivyErrorExcerptSize)
		if errMsg == "" {
			errMsg = readTempFileExcerptInternal(stdoutFile, trivyErrorExcerptSize)
		}
		if errMsg == "" {
			errMsg = fmt.Sprintf("exit status %d", execInspect.ExitCode)
		}
		logTrivyScanFailureDiagnosticsInternal(ctx, imageName, imageID, int64(execInspect.ExitCode), stdoutFile, stderrFile, "exec non-zero exit")
		return nil, formatTrivyExitErrorInternal(int64(execInspect.ExitCode), errMsg, imageName)
	}

	trivyOutput, err := readTrivyOutputFromContainerFileInternal(ctx, dockerClient, containerID, outputPath)
	if err != nil {
		slog.WarnContext(ctx,
			"failed to read trivy output file from batch container; falling back to stdout parsing",
			"containerId", containerID,
			"outputPath", outputPath,
			"error", err,
		)
		trivyOutput = nil
	}

	var trivyReport *vulnerability.TrivyReport
	if len(trivyOutput) > 0 {
		trivyReport, err = decodeTrivyReportFromBytesInternal(trivyOutput)
	} else {
		trivyReport, err = decodeTrivyReportFromFileInternal(stdoutFile)
	}
	if err != nil {
		if errors.Is(err, io.EOF) {
			errMsg := readTempFileExcerptInternal(stderrFile, trivyErrorExcerptSize)
			if errMsg == "" {
				errMsg = "trivy scan produced no output"
			}
			logTrivyScanFailureDiagnosticsInternal(ctx, imageName, imageID, int64(execInspect.ExitCode), stdoutFile, stderrFile, "exec empty output")
			return nil, fmt.Errorf("trivy scan failed: %s", errMsg)
		}

		logTrivyScanFailureDiagnosticsInternal(ctx, imageName, imageID, int64(execInspect.ExitCode), stdoutFile, stderrFile, "exec parse error")
		return nil, fmt.Errorf("failed to parse trivy output: %w", err)
	}

	if trivyReport == nil {
		errMsg := readTempFileExcerptInternal(stderrFile, trivyErrorExcerptSize)
		if errMsg == "" {
			errMsg = "trivy scan produced no output"
		}
		logTrivyScanFailureDiagnosticsInternal(ctx, imageName, imageID, int64(execInspect.ExitCode), stdoutFile, stderrFile, "exec nil report")
		return nil, fmt.Errorf("trivy scan failed: %s", errMsg)
	}

	result := vulnerability.ConvertTrivyReportToScanResult(trivyReport, imageID, time.Now(), 0)
	result.ScannerVersion = scannerVersion

	return result, nil
}

// DeleteScanResult deletes the scan result for an image
func (s *VulnerabilityService) DeleteScanResult(ctx context.Context, imageID string) error {
	if s.db == nil {
		return nil
	}

	return s.db.WithContext(ctx).Where("id = ?", imageID).Delete(&models.VulnerabilityScanRecord{}).Error
}

// CleanupOrphanedScanRecords removes vulnerability scan records for images that
// no longer exist in Docker. This keeps "images scanned" counts in sync (e.g.
// avoids "5/3" when images were deleted after being scanned). Safe to call
// even when no images exist; returns the number of records deleted.
func (s *VulnerabilityService) CleanupOrphanedScanRecords(ctx context.Context) (deleted int64, err error) {
	if s.db == nil {
		return 0, nil
	}

	dockerClient, err := s.dockerService.GetClient()
	if err != nil {
		return 0, fmt.Errorf("failed to connect to Docker: %w", err)
	}

	images, err := dockerClient.ImageList(ctx, imagetypes.ListOptions{})
	if err != nil {
		return 0, fmt.Errorf("failed to list images: %w", err)
	}

	currentIDs := make(map[string]struct{}, len(images))
	for _, img := range images {
		currentIDs[img.ID] = struct{}{}
	}

	// Build list for NOT IN. If no images, we delete all scan records.
	var ids []string
	if len(currentIDs) > 0 {
		ids = make([]string, 0, len(currentIDs))
		for id := range currentIDs {
			ids = append(ids, id)
		}
	}

	var result *gorm.DB
	if len(ids) == 0 {
		result = s.db.WithContext(ctx).Where("1 = 1").Delete(&models.VulnerabilityScanRecord{})
	} else {
		result = s.db.WithContext(ctx).Where("id NOT IN ?", ids).Delete(&models.VulnerabilityScanRecord{})
	}
	if result.Error != nil {
		return 0, result.Error
	}

	return result.RowsAffected, nil
}

// GetTrivyVersion returns the Trivy version from the Trivy container image
func (s *VulnerabilityService) GetTrivyVersion(ctx context.Context) string {
	dockerClient, err := s.dockerService.GetClient()
	if err != nil {
		return ""
	}

	trivyImage, err := s.ensureTrivyImageInternal(ctx)
	if err != nil {
		return ""
	}

	config := &containertypes.Config{
		Image: trivyImage,
		Cmd:   []string{"--version"},
		Labels: map[string]string{
			libarcane.InternalResourceLabel: "true",
		},
	}

	hostConfig := &containertypes.HostConfig{
		AutoRemove: true,
	}

	resp, err := dockerClient.ContainerCreate(ctx, config, hostConfig, nil, nil, "")
	if err != nil {
		return ""
	}

	if err := dockerClient.ContainerStart(ctx, resp.ID, containertypes.StartOptions{}); err != nil {
		_ = dockerClient.ContainerRemove(ctx, resp.ID, containertypes.RemoveOptions{Force: true})
		return ""
	}

	logs, err := dockerClient.ContainerLogs(ctx, resp.ID, containertypes.LogsOptions{
		ShowStdout: true,
		ShowStderr: true,
		Follow:     true,
	})
	if err != nil {
		_ = dockerClient.ContainerRemove(ctx, resp.ID, containertypes.RemoveOptions{Force: true})
		return ""
	}
	var closeLogsOnce sync.Once
	closeLogs := func() {
		closeLogsOnce.Do(func() {
			if closeErr := logs.Close(); closeErr != nil && !isExpectedDockerStreamEndErrorInternal(closeErr) {
				slog.WarnContext(ctx, "failed to close trivy version logs stream", "error", closeErr)
			}
		})
	}
	defer closeLogs()

	stdoutFile, err := createTrivyLogTempFileInternal("trivy-version-stdout-*")
	if err != nil {
		return ""
	}

	stderrFile, err := createTrivyLogTempFileInternal("trivy-version-stderr-*")
	if err != nil {
		cleanupTrivyLogTempFilesInternal(ctx, stdoutFile)
		return ""
	}
	defer cleanupTrivyLogTempFilesInternal(ctx, stdoutFile, stderrFile)

	logDone := startDockerLogCopyInternal(logs, stdoutFile, stderrFile)

	statusCh, errCh := dockerClient.ContainerWait(ctx, resp.ID, containertypes.WaitConditionNotRunning)
	var waitResp containertypes.WaitResponse
	select {
	case err := <-errCh:
		if err != nil {
			return ""
		}
	case waitResp = <-statusCh:
	}

	closeLogs()

	if err := waitForDockerLogCopyInternal(logDone); err != nil {
		return ""
	}

	if waitResp.StatusCode != 0 {
		return ""
	}

	return parseTrivyVersion(readTempFileExcerptInternal(stdoutFile, trivyErrorExcerptSize))
}

func parseTrivyVersion(output string) string {
	output = strings.TrimSpace(output)
	if output == "" {
		return ""
	}
	lines := strings.SplitSeq(output, "\n")
	for line := range lines {
		if after, ok := strings.CutPrefix(line, "Version:"); ok {
			return strings.TrimSpace(after)
		}
	}
	return strings.TrimSpace(output)
}

func (s *VulnerabilityService) getTrivyImageRef() string {
	if s.settingsService == nil {
		return DefaultTrivyImage
	}

	cfg := s.settingsService.GetSettingsConfig()
	if cfg == nil {
		return DefaultTrivyImage
	}

	override := strings.TrimSpace(cfg.TrivyImage.Value)
	if override == "" {
		return DefaultTrivyImage
	}

	return override
}

func (s *VulnerabilityService) getTrivyScanTimeoutArg() string {
	timeoutSeconds := 0
	if s.settingsService != nil {
		timeoutSeconds = s.settingsService.GetSettingsConfig().TrivyScanTimeout.AsInt()
	}

	return timeouts.GetDuration(timeoutSeconds, timeouts.DefaultTrivyScan).String()
}

func newTrivyOutputPathInternal() string {
	return trivyOutputPathPrefix + strconv.FormatInt(time.Now().UnixNano(), 10) + ".json"
}

func (s *VulnerabilityService) getTrivySingleScanCacheDirForSlotInternal(slotID int) string {
	if slotID < 0 {
		slotID = 0
	}

	// Use a fixed cache directory per concurrency slot on the shared cache
	// volume. This avoids Trivy fs-cache lock contention while bounding cache
	// growth to the configured slot count.
	return fmt.Sprintf("%s/slot-%d", trivyCacheSlotRootDir, slotID)
}

func (s *VulnerabilityService) ensureTrivyImageInternal(ctx context.Context) (string, error) {
	dockerClient, err := s.dockerService.GetClient()
	if err != nil {
		return "", fmt.Errorf("failed to connect to Docker: %w", err)
	}

	trivyImage := s.getTrivyImageRef()
	if _, err := dockerClient.ImageInspect(ctx, trivyImage); err == nil {
		return trivyImage, nil
	}

	pullTimeoutSeconds := 0
	if s.settingsService != nil && s.settingsService.GetSettingsConfig() != nil {
		pullTimeoutSeconds = s.settingsService.GetSettingsConfig().DockerImagePullTimeout.AsInt()
	}

	pullCtx, pullCancel := timeouts.WithTimeout(ctx, pullTimeoutSeconds, timeouts.DefaultDockerImagePull)
	defer pullCancel()

	pullReader, err := dockerClient.ImagePull(pullCtx, trivyImage, imagetypes.PullOptions{})
	if err != nil {
		if errors.Is(pullCtx.Err(), context.DeadlineExceeded) {
			return "", fmt.Errorf("trivy image pull timed out for %s (increase DOCKER_IMAGE_PULL_TIMEOUT or setting)", trivyImage)
		}
		return "", fmt.Errorf("pull trivy image %s: %w", trivyImage, err)
	}
	_, _ = io.Copy(io.Discard, pullReader)
	_ = pullReader.Close()

	return trivyImage, nil
}

func (s *VulnerabilityService) ensureTrivyCacheVolumeInternal(ctx context.Context) (string, error) {
	dockerClient, err := s.dockerService.GetClient()
	if err != nil {
		return "", err
	}

	if _, err := dockerClient.VolumeInspect(ctx, trivyCacheVolumeName); err == nil {
		return trivyCacheVolumeName, nil
	}

	_, err = dockerClient.VolumeCreate(ctx, volumetypes.CreateOptions{
		Name: trivyCacheVolumeName,
		Labels: map[string]string{
			libarcane.InternalResourceLabel: "true",
		},
	})
	if err != nil {
		return "", fmt.Errorf("failed to create trivy cache volume: %w", err)
	}

	return trivyCacheVolumeName, nil
}

// runTrivyScan executes Trivy scan on an image
func (s *VulnerabilityService) getTrivyConfigFiles() (configContent, ignoreContent string, err error) {
	if s.settingsService == nil {
		return "", "", nil
	}

	cfg := s.settingsService.GetSettingsConfig()
	if cfg == nil {
		return "", "", nil
	}

	return cfg.TrivyConfig.Value, cfg.TrivyIgnore.Value, nil
}

func (s *VulnerabilityService) createTrivyConfigTempFile(ctx context.Context, content string) (string, bool) {
	configFile, err := os.CreateTemp("", "trivy-config-*.yaml")
	if err != nil {
		slog.WarnContext(ctx, "failed to create trivy config temp file", "error", err)
		return "", false
	}
	if _, err := configFile.WriteString(content); err != nil {
		slog.WarnContext(ctx, "failed to write trivy config", "error", err)
		_ = configFile.Close()
		_ = os.Remove(configFile.Name()) //nolint:gosec // temp file path is generated by os.CreateTemp
		return "", false
	}
	_ = configFile.Close()
	return configFile.Name(), true
}

func (s *VulnerabilityService) createTrivyIgnoreTempFile(ctx context.Context, content string) (string, bool) {
	ignoreFile, err := os.CreateTemp("", "trivy-ignore-*")
	if err != nil {
		slog.WarnContext(ctx, "failed to create trivy ignore temp file", "error", err)
		return "", false
	}
	if _, err := ignoreFile.WriteString(content); err != nil {
		slog.WarnContext(ctx, "failed to write trivy ignore", "error", err)
		_ = ignoreFile.Close()
		_ = os.Remove(ignoreFile.Name()) //nolint:gosec // temp file path is generated by os.CreateTemp
		return "", false
	}
	_ = ignoreFile.Close()
	return ignoreFile.Name(), true
}

func cleanupTempFiles(ctx context.Context, tempFiles []string) {
	for _, f := range tempFiles {
		if err := os.Remove(f); err != nil {
			slog.WarnContext(ctx, "failed to remove trivy temp file", "path", f, "error", err)
		}
	}
}

func (s *VulnerabilityService) buildTrivyCommandArgs(
	ctx context.Context,
	imageName string,
	configContent string,
	ignoreContent string,
	cacheDir string,
	outputPath string,
) ([]string, []string) {
	cmdArgs := []string{"image", "--format", "json", "--quiet", "--timeout", s.getTrivyScanTimeoutArg()}
	var tempFiles []string

	if strings.TrimSpace(configContent) != "" {
		if tempFile, ok := s.createTrivyConfigTempFile(ctx, configContent); ok {
			tempFiles = append(tempFiles, tempFile)
			cmdArgs = append(cmdArgs, "--config", "/tmp/trivy-config.yaml")
		}
	}

	if strings.TrimSpace(ignoreContent) != "" {
		if tempFile, ok := s.createTrivyIgnoreTempFile(ctx, ignoreContent); ok {
			tempFiles = append(tempFiles, tempFile)
			cmdArgs = append(cmdArgs, "--ignorefile", "/tmp/trivy-ignore")
		}
	}

	if strings.TrimSpace(cacheDir) != "" {
		cmdArgs = append(cmdArgs, "--cache-dir", cacheDir)
	}

	if strings.TrimSpace(outputPath) != "" {
		cmdArgs = append(cmdArgs, "--output", outputPath)
	}

	cmdArgs = append(cmdArgs, imageName)

	return cmdArgs, tempFiles
}

func buildTrivyContainerConfig(trivyImage string, cmdArgs []string) *containertypes.Config {
	return &containertypes.Config{
		Image: trivyImage,
		Cmd:   cmdArgs,
		Labels: map[string]string{
			libarcane.InternalResourceLabel: "true",
		},
	}
}

func buildTrivyHostConfig(cacheVolume string, tempFiles []string, resources containertypes.Resources, cpuSet string, applyLimits bool) *containertypes.HostConfig {
	hostConfig := &containertypes.HostConfig{
		// Keep single-scan containers until explicit cleanup so we can reliably
		// wait for completion and collect logs across Docker variants.
		AutoRemove: false,
		Mounts: []mounttypes.Mount{
			{
				Type:   mounttypes.TypeBind,
				Source: "/var/run/docker.sock",
				Target: "/var/run/docker.sock",
			},
			{
				Type:   mounttypes.TypeVolume,
				Source: cacheVolume,
				Target: trivyCacheMountTarget,
			},
		},
	}

	applyTrivyContainerResourcesInternal(hostConfig, resources, cpuSet, applyLimits)

	addTrivyTempFileMounts(hostConfig, tempFiles)
	return hostConfig
}

func applyTrivyContainerResourcesInternal(hostConfig *containertypes.HostConfig, resources containertypes.Resources, cpuSet string, applyLimits bool) {
	if hostConfig == nil || !applyLimits {
		return
	}

	if cpuSet != "" {
		resources.NanoCPUs = 0
		resources.CpusetCpus = cpuSet
	}

	hostConfig.Resources = resources
}

func addTrivyTempFileMounts(hostConfig *containertypes.HostConfig, tempFiles []string) {
	for _, tempFile := range tempFiles {
		switch {
		case strings.Contains(tempFile, "trivy-config"):
			hostConfig.Mounts = append(hostConfig.Mounts, mounttypes.Mount{
				Type:     mounttypes.TypeBind,
				Source:   tempFile,
				Target:   "/tmp/trivy-config.yaml",
				ReadOnly: true,
			})
		case strings.Contains(tempFile, "trivy-ignore"):
			hostConfig.Mounts = append(hostConfig.Mounts, mounttypes.Mount{
				Type:     mounttypes.TypeBind,
				Source:   tempFile,
				Target:   "/tmp/trivy-ignore",
				ReadOnly: true,
			})
		}
	}
}

func createTrivyLogTempFileInternal(prefix string) (*os.File, error) {
	file, err := os.CreateTemp("", prefix)
	if err != nil {
		return nil, err
	}
	return file, nil
}

func cleanupTrivyLogTempFilesInternal(ctx context.Context, files ...*os.File) {
	for _, file := range files {
		if file == nil {
			continue
		}

		path := file.Name()
		if err := file.Close(); err != nil {
			slog.WarnContext(ctx, "failed to close trivy temp file", "path", path, "error", err)
		}

		if path == "" {
			continue
		}

		if err := os.Remove(path); err != nil { //nolint:gosec // temp file path comes from os.CreateTemp
			slog.WarnContext(ctx, "failed to remove trivy temp file", "path", path, "error", err)
		}
	}
}

func startDockerLogCopyInternal(stream io.Reader, stdoutWriter, stderrWriter io.Writer) <-chan error {
	logDone := make(chan error, 1)
	go func() {
		_, err := stdcopy.StdCopy(stdoutWriter, stderrWriter, stream)
		logDone <- err
	}()
	return logDone
}

func waitForDockerLogCopyInternal(logDone <-chan error) error {
	err := <-logDone
	if err == nil || isExpectedDockerStreamEndErrorInternal(err) {
		return nil
	}
	return err
}

func trivyMountSummariesInternal(hostConfig *containertypes.HostConfig) []string {
	if hostConfig == nil || len(hostConfig.Mounts) == 0 {
		return nil
	}

	summaries := make([]string, 0, len(hostConfig.Mounts))
	for _, mount := range hostConfig.Mounts {
		source := mount.Source
		if source == "" {
			source = string(mount.Type)
		}
		summaries = append(summaries, fmt.Sprintf("%s:%s", source, mount.Target))
	}

	return summaries
}

func logTrivyContainerStartupRequestInternal(ctx context.Context, scope string, config *containertypes.Config, hostConfig *containertypes.HostConfig) {
	if config == nil {
		return
	}

	resources := containertypes.Resources{}
	autoRemove := false
	mounts := []string{}
	if hostConfig != nil {
		resources = hostConfig.Resources
		autoRemove = hostConfig.AutoRemove
		mounts = trivyMountSummariesInternal(hostConfig)
	}

	slog.DebugContext(ctx,
		"preparing trivy container startup",
		"scope", scope,
		"image", config.Image,
		"cmd", config.Cmd,
		"entrypoint", config.Entrypoint,
		"autoRemove", autoRemove,
		"mounts", mounts,
		"nanoCPUs", resources.NanoCPUs,
		"cpuset", resources.CpusetCpus,
		"memory", resources.Memory,
		"memorySwap", resources.MemorySwap,
	)
}

func truncateTrivyLogOutputInternal(content string, maxBytes int64) string {
	content = strings.TrimSpace(content)
	if content == "" || maxBytes <= 0 {
		return content
	}

	raw := []byte(content)
	if int64(len(raw)) <= maxBytes {
		return content
	}

	return strings.TrimSpace(string(raw[:maxBytes])) + " ...<truncated>"
}

func readTrivyStartupLogsInternal(ctx context.Context, dockerClient *client.Client, containerID string) (string, string) {
	if dockerClient == nil || containerID == "" {
		return "", ""
	}

	logsCtx, logsCancel := timeouts.WithTimeout(ctx, 0, timeouts.DefaultDockerAPI)
	defer logsCancel()

	logs, err := dockerClient.ContainerLogs(logsCtx, containerID, containertypes.LogsOptions{
		ShowStdout: true,
		ShowStderr: true,
		Tail:       "200",
	})
	if err != nil {
		slog.DebugContext(ctx, "failed to read trivy startup logs", "containerId", containerID, "error", err)
		return "", ""
	}
	defer func() {
		if closeErr := logs.Close(); closeErr != nil {
			slog.WarnContext(ctx, "failed to close trivy startup logs stream", "containerId", containerID, "error", closeErr)
		}
	}()

	var stdoutBuf bytes.Buffer
	var stderrBuf bytes.Buffer
	if _, err := stdcopy.StdCopy(&stdoutBuf, &stderrBuf, logs); err != nil && !isExpectedDockerStreamEndErrorInternal(err) {
		slog.DebugContext(ctx, "failed to decode trivy startup logs", "containerId", containerID, "error", err)
	}

	stdoutLog := truncateTrivyLogOutputInternal(stdoutBuf.String(), trivyErrorExcerptSize)
	stderrLog := truncateTrivyLogOutputInternal(stderrBuf.String(), trivyErrorExcerptSize)
	return stdoutLog, stderrLog
}

func removeDockerContainerInternal(ctx context.Context, dockerClient *client.Client, containerID, warningMessage string) {
	if dockerClient == nil || containerID == "" {
		return
	}

	cleanupCtx := context.WithoutCancel(ctx)
	cleanupCtx, cleanupCancel := timeouts.WithTimeout(cleanupCtx, 0, timeouts.DefaultDockerAPI)
	defer cleanupCancel()

	if err := dockerClient.ContainerRemove(cleanupCtx, containerID, containertypes.RemoveOptions{Force: true}); err != nil && !cerrdefs.IsNotFound(err) {
		slog.WarnContext(cleanupCtx, warningMessage, "containerId", containerID, "error", err)
	}
}

func (s *VulnerabilityService) createAndStartTrivyContainerInternal(
	ctx context.Context,
	dockerClient *client.Client,
	scope string,
	config *containertypes.Config,
	hostConfig *containertypes.HostConfig,
) (string, error) {
	logTrivyContainerStartupRequestInternal(ctx, scope, config, hostConfig)

	createCtx, createCancel := timeouts.WithTimeout(ctx, 0, timeouts.DefaultDockerAPI)
	defer createCancel()

	resp, err := dockerClient.ContainerCreate(createCtx, config, hostConfig, nil, nil, "")
	if err != nil {
		slog.WarnContext(ctx, "failed to create trivy container", "scope", scope, "error", err)
		return "", fmt.Errorf("failed to create container: %w", err)
	}

	startCtx, startCancel := timeouts.WithTimeout(ctx, 0, timeouts.DefaultDockerAPI)
	defer startCancel()

	if err := dockerClient.ContainerStart(startCtx, resp.ID, containertypes.StartOptions{}); err != nil {
		stdoutLog, stderrLog := readTrivyStartupLogsInternal(ctx, dockerClient, resp.ID)
		slog.WarnContext(ctx,
			"failed to start trivy container",
			"scope", scope,
			"containerId", resp.ID,
			"error", err,
			"stdout", stdoutLog,
			"stderr", stderrLog,
		)

		removeDockerContainerInternal(ctx, dockerClient, resp.ID, "failed to cleanup trivy container after start failure")
		return "", fmt.Errorf("failed to start container: %w", err)
	}

	return resp.ID, nil
}

func parseTrivyCPULimitInternal(raw string, fallback float64) float64 {
	raw = strings.TrimSpace(raw)
	if raw == "" {
		return fallback
	}

	limit, err := strconv.ParseFloat(raw, 64)
	if err != nil {
		return fallback
	}

	if limit < 0 {
		return 0
	}

	return limit
}

func parseTrivyMemoryLimitMBInternal(raw string, fallback int64) int64 {
	raw = strings.TrimSpace(raw)
	if raw == "" {
		return fallback
	}

	limit, err := strconv.ParseInt(raw, 10, 64)
	if err != nil {
		return fallback
	}

	if limit < 0 {
		return 0
	}

	return limit
}

func trivyContainerWaitTimeoutInternal(trivyTimeoutArg string) time.Duration {
	trivyTimeoutArg = strings.TrimSpace(trivyTimeoutArg)
	if trivyTimeoutArg == "" {
		return timeouts.DefaultTrivyScan + timeouts.DefaultDockerAPI
	}

	timeout, err := time.ParseDuration(trivyTimeoutArg)
	if err != nil || timeout <= 0 {
		return timeouts.DefaultTrivyScan + timeouts.DefaultDockerAPI
	}

	return timeout + timeouts.DefaultDockerAPI
}

func isSynologyDockerHostInternal(operatingSystem string) bool {
	// Docker info may return a multi-line OS string on some Synology models.
	// e.g. DS925+ (Kernel 5.x) returns "Synology NAS\n (containerized)".
	// Check each line independently so a match on any line is sufficient.
	for line := range strings.SplitSeq(operatingSystem, "\n") {
		if strings.Contains(strings.ToLower(strings.TrimSpace(line)), "synology") {
			return true
		}
	}
	return false
}

func buildTrivyCPUSetInternal(nanoCPUs int64, hostCPUs int) string {
	if nanoCPUs <= 0 {
		return ""
	}

	if hostCPUs <= 0 {
		hostCPUs = 1
	}

	requestedCPUs := int(math.Floor(float64(nanoCPUs) / float64(trivyNanoCPUsPerCore)))
	if requestedCPUs < 1 {
		requestedCPUs = 1
	}
	if requestedCPUs > hostCPUs {
		requestedCPUs = hostCPUs
	}

	if requestedCPUs == 1 {
		return "0"
	}

	return fmt.Sprintf("0-%d", requestedCPUs-1)
}

func (s *VulnerabilityService) getTrivyContainerResourcesInternal() (containertypes.Resources, bool) {
	var cfg *models.Settings
	if s.settingsService != nil {
		cfg = s.settingsService.GetSettingsConfig()
	}

	return buildTrivyContainerResourcesInternal(cfg)
}

func (s *VulnerabilityService) getTrivyContainerResourceOptionsInternal(ctx context.Context, dockerClient *client.Client) (containertypes.Resources, string, bool) {
	resources, applyLimits := s.getTrivyContainerResourcesInternal()
	if !applyLimits || dockerClient == nil {
		return resources, "", applyLimits
	}

	infoCtx, infoCancel := timeouts.WithTimeout(ctx, 0, timeouts.DefaultDockerAPI)
	defer infoCancel()

	slog.DebugContext(ctx, "inspecting docker host for trivy resource strategy")

	info, err := dockerClient.Info(infoCtx)
	if err != nil {
		if errors.Is(infoCtx.Err(), context.DeadlineExceeded) || errors.Is(err, context.DeadlineExceeded) {
			slog.WarnContext(ctx,
				"timed out inspecting docker info for trivy resource strategy; falling back to default limits",
				"timeout", timeouts.DefaultDockerAPI.String(),
				"error", err,
			)
		} else {
			slog.DebugContext(ctx, "failed to inspect docker info for trivy resource strategy", "error", err)
		}
		return resources, "", applyLimits
	}

	slog.DebugContext(ctx,
		"resolved docker host info for trivy resource strategy",
		"operatingSystem", info.OperatingSystem,
		"ncpu", info.NCPU,
	)

	if !isSynologyDockerHostInternal(info.OperatingSystem) {
		return resources, "", applyLimits
	}

	cpuSet := buildTrivyCPUSetInternal(resources.NanoCPUs, info.NCPU)
	resources.NanoCPUs = 0

	if cpuSet != "" {
		slog.InfoContext(ctx,
			"detected Synology Docker host; applying Trivy CPU limit via cpuset",
			"operatingSystem", info.OperatingSystem,
			"cpuset", cpuSet,
		)
	} else {
		slog.InfoContext(ctx,
			"detected Synology Docker host; skipping Trivy NanoCPUs limit",
			"operatingSystem", info.OperatingSystem,
		)
	}

	return resources, cpuSet, applyLimits
}

func isExpectedDockerStreamEndErrorInternal(err error) bool {
	if err == nil {
		return false
	}

	if errors.Is(err, io.EOF) || errors.Is(err, net.ErrClosed) || errors.Is(err, context.Canceled) {
		return true
	}

	errMsg := strings.ToLower(err.Error())
	return strings.Contains(errMsg, "use of closed network connection") ||
		strings.Contains(errMsg, "context canceled") ||
		strings.Contains(errMsg, "broken pipe") ||
		strings.Contains(errMsg, "connection reset by peer")
}

func tempFileSizeInternal(file *os.File) int64 {
	if file == nil {
		return 0
	}

	stat, err := file.Stat()
	if err != nil {
		return 0
	}

	return stat.Size()
}

func readTempFileExcerptInternal(file *os.File, maxBytes int64) string {
	if file == nil {
		return ""
	}

	if _, err := file.Seek(0, io.SeekStart); err != nil {
		return ""
	}

	reader := io.Reader(file)
	if maxBytes > 0 {
		reader = io.LimitReader(file, maxBytes)
	}

	content, err := io.ReadAll(reader)
	if err != nil {
		return ""
	}

	return strings.TrimSpace(string(content))
}

func readTrivyOutputFromContainerFileInternal(ctx context.Context, dockerClient *client.Client, containerID, outputPath string) ([]byte, error) {
	if dockerClient == nil {
		return nil, errors.New("docker client is nil")
	}
	if containerID == "" {
		return nil, errors.New("container id is empty")
	}
	if strings.TrimSpace(outputPath) == "" {
		return nil, errors.New("trivy output path is empty")
	}

	copyCtx, copyCancel := timeouts.WithTimeout(ctx, 0, timeouts.DefaultDockerAPI)
	defer copyCancel()

	archiveReader, _, err := dockerClient.CopyFromContainer(copyCtx, containerID, outputPath)
	if err != nil {
		return nil, fmt.Errorf("copy trivy output file: %w", err)
	}
	defer func() {
		if closeErr := archiveReader.Close(); closeErr != nil && !isExpectedDockerStreamEndErrorInternal(closeErr) {
			slog.WarnContext(ctx,
				"failed to close trivy output archive stream",
				"containerId", containerID,
				"outputPath", outputPath,
				"error", closeErr,
			)
		}
	}()

	rawOutput, err := extractFileFromContainerArchiveInternal(archiveReader)
	if err != nil {
		return nil, fmt.Errorf("extract trivy output file: %w", err)
	}

	if len(bytes.TrimSpace(rawOutput)) == 0 {
		return nil, io.EOF
	}

	return rawOutput, nil
}

func cleanupTrivyOutputFileInContainerInternal(ctx context.Context, dockerClient *client.Client, containerID, outputPath string) {
	if dockerClient == nil || containerID == "" || strings.TrimSpace(outputPath) == "" {
		return
	}

	execCtx, execCancel := timeouts.WithTimeout(ctx, 0, timeouts.DefaultDockerAPI)
	defer execCancel()

	execResp, err := dockerClient.ContainerExecCreate(execCtx, containerID, containertypes.ExecOptions{
		Cmd: []string{"rm", "-f", outputPath},
	})
	if err != nil {
		slog.DebugContext(ctx,
			"failed to create cleanup exec for trivy output file",
			"containerId", containerID,
			"outputPath", outputPath,
			"error", err,
		)
		return
	}

	if err := dockerClient.ContainerExecStart(execCtx, execResp.ID, containertypes.ExecStartOptions{}); err != nil {
		slog.DebugContext(ctx,
			"failed to start cleanup exec for trivy output file",
			"containerId", containerID,
			"outputPath", outputPath,
			"error", err,
		)
		return
	}
}

func extractFileFromContainerArchiveInternal(archiveReader io.Reader) ([]byte, error) {
	if archiveReader == nil {
		return nil, errors.New("container archive reader is nil")
	}

	tarReader := tar.NewReader(archiveReader)
	for {
		header, err := tarReader.Next()
		if errors.Is(err, io.EOF) {
			break
		}
		if err != nil {
			return nil, fmt.Errorf("read tar header: %w", err)
		}

		if header == nil || header.Typeflag == tar.TypeDir {
			continue
		}

		if header.Typeflag != tar.TypeReg {
			continue
		}

		data, err := io.ReadAll(tarReader)
		if err != nil {
			return nil, fmt.Errorf("read tar file content: %w", err)
		}

		return data, nil
	}

	return nil, errors.New("container archive did not include a file")
}

func decodeTrivyReportFromFileInternal(file *os.File) (*vulnerability.TrivyReport, error) {
	if file == nil {
		return nil, errors.New("trivy output file is nil")
	}

	if _, err := file.Seek(0, io.SeekStart); err != nil {
		return nil, fmt.Errorf("failed to seek trivy output file: %w", err)
	}

	rawOutput, err := io.ReadAll(file)
	if err != nil {
		return nil, fmt.Errorf("failed to read trivy output file: %w", err)
	}

	return decodeTrivyReportFromBytesInternal(rawOutput)
}

func decodeTrivyReportFromBytesInternal(rawOutput []byte) (*vulnerability.TrivyReport, error) {
	trimmedOutput := bytes.TrimSpace(rawOutput)
	if len(trimmedOutput) == 0 {
		return nil, io.EOF
	}

	report, strictErr := decodeSingleTrivyReportInternal(trimmedOutput)
	if strictErr == nil {
		return report, nil
	}

	// Trivy output can occasionally include non-JSON log lines or additional JSON
	// objects around the report depending on Docker variant / stream behavior.
	// Extract top-level JSON objects and return the first valid Trivy report.
	jsonCandidates := extractTopLevelJSONObjectCandidatesInternal(trimmedOutput)
	if len(jsonCandidates) == 0 {
		return nil, strictErr
	}

	lastErr := strictErr
	for _, candidate := range jsonCandidates {
		report, err := decodeSingleTrivyReportInternal(candidate)
		if err == nil {
			return report, nil
		}
		lastErr = err
	}

	if lastErr != nil {
		return nil, lastErr
	}

	return nil, errors.New("trivy output did not contain a valid report")
}

func decodeSingleTrivyReportInternal(rawOutput []byte) (*vulnerability.TrivyReport, error) {
	decoder := json.NewDecoder(bytes.NewReader(rawOutput))

	var report vulnerability.TrivyReport
	if err := decoder.Decode(&report); err != nil {
		return nil, err
	}

	if !isLikelyTrivyReportInternal(&report) {
		return nil, errors.New("decoded JSON object is not a trivy report")
	}

	if hasTrailingNonWhitespaceInternal(rawOutput, decoder.InputOffset()) {
		return nil, errors.New("trivy output contains trailing data")
	}

	return &report, nil
}

func hasTrailingNonWhitespaceInternal(rawOutput []byte, offset int64) bool {
	if offset < 0 {
		return len(bytes.TrimSpace(rawOutput)) > 0
	}

	if offset >= int64(len(rawOutput)) {
		return false
	}

	return len(bytes.TrimSpace(rawOutput[offset:])) > 0
}

func isLikelyTrivyReportInternal(report *vulnerability.TrivyReport) bool {
	if report == nil {
		return false
	}

	return report.SchemaVersion > 0 ||
		strings.TrimSpace(report.ArtifactName) != "" ||
		strings.TrimSpace(report.ArtifactType) != "" ||
		len(report.Results) > 0
}

func extractTopLevelJSONObjectCandidatesInternal(rawOutput []byte) [][]byte {
	if len(rawOutput) == 0 {
		return nil
	}

	candidates := make([][]byte, 0, 4)
	start := -1
	depth := 0
	inString := false
	escaped := false

	for i, b := range rawOutput {
		if start == -1 {
			if b == '{' {
				start = i
				depth = 1
				inString = false
				escaped = false
			}
			continue
		}

		if inString {
			if escaped {
				escaped = false
				continue
			}

			switch b {
			case '\\':
				escaped = true
			case '"':
				inString = false
			}
			continue
		}

		switch b {
		case '"':
			inString = true
		case '{':
			depth++
		case '}':
			depth--
			if depth == 0 {
				candidate := bytes.TrimSpace(rawOutput[start : i+1])
				if len(candidate) > 0 {
					candidates = append(candidates, candidate)
				}
				start = -1
			}
		}
	}

	return candidates
}

func logTrivyScanFailureDiagnosticsInternal(ctx context.Context, imageName, imageID string, exitCode int64, stdoutFile, stderrFile *os.File, reason string) {
	slog.WarnContext(ctx,
		"trivy scan diagnostics",
		"image", imageName,
		"imageId", imageID,
		"reason", reason,
		"exitCode", exitCode,
		"stdoutBytes", tempFileSizeInternal(stdoutFile),
		"stderrBytes", tempFileSizeInternal(stderrFile),
	)
}

func formatTrivyExitErrorInternal(exitCode int64, errMsg, imageName string) error {
	errMsg = strings.TrimSpace(errMsg)

	if exitCode == 137 {
		if errMsg == "" || errMsg == fmt.Sprintf("exit status %d", exitCode) {
			return fmt.Errorf("trivy scan failed: process killed with exit status 137 (likely out of memory while scanning %s)", imageName)
		}
		return fmt.Errorf("trivy scan failed: %s (process killed with exit status 137; likely out of memory)", errMsg)
	}

	if strings.Contains(strings.ToLower(errMsg), "deadline exceeded") {
		return fmt.Errorf("trivy scan timed out for %s (increase TRIVY_SCAN_TIMEOUT or trivyScanTimeout setting)", imageName)
	}

	return fmt.Errorf("trivy scan failed: %s", errMsg)
}

func buildTrivyContainerResourcesInternal(cfg *models.Settings) (containertypes.Resources, bool) {
	limitsEnabled := true
	cpuLimitCores := defaultTrivyCPULimitCores
	memoryLimitMB := defaultTrivyMemoryLimitMB

	if cfg != nil {
		limitsEnabled = cfg.TrivyResourceLimitsEnabled.IsTrue()
		cpuLimitCores = parseTrivyCPULimitInternal(cfg.TrivyCpuLimit.Value, defaultTrivyCPULimitCores)
		memoryLimitMB = parseTrivyMemoryLimitMBInternal(cfg.TrivyMemoryLimitMb.Value, defaultTrivyMemoryLimitMB)
	}

	if !limitsEnabled {
		return containertypes.Resources{}, false
	}

	resources := containertypes.Resources{}
	if cpuLimitCores > 0 {
		resources.NanoCPUs = int64(cpuLimitCores * float64(trivyNanoCPUsPerCore))
	}

	if memoryLimitMB > 0 {
		memoryBytes := memoryLimitMB * trivyBytesPerMB
		resources.Memory = memoryBytes
		resources.MemorySwap = memoryBytes
	}

	return resources, true
}

func (s *VulnerabilityService) runTrivyContainer(
	ctx context.Context,
	dockerClient *client.Client,
	imageID string,
	config *containertypes.Config,
	hostConfig *containertypes.HostConfig,
) (*os.File, *os.File, int64, int64, string, error) {
	stdoutFile, err := createTrivyLogTempFileInternal("trivy-stdout-*")
	if err != nil {
		return nil, nil, 0, 0, "", fmt.Errorf("failed to create trivy stdout temp file: %w", err)
	}

	stderrFile, err := createTrivyLogTempFileInternal("trivy-stderr-*")
	if err != nil {
		cleanupTrivyLogTempFilesInternal(ctx, stdoutFile)
		return nil, nil, 0, 0, "", fmt.Errorf("failed to create trivy stderr temp file: %w", err)
	}

	success := false
	containerID := ""
	defer func() {
		if !success {
			removeDockerContainerInternal(ctx, dockerClient, containerID, "failed to cleanup trivy scan container")
			cleanupTrivyLogTempFilesInternal(ctx, stdoutFile, stderrFile)
		}
	}()

	containerID, err = s.createAndStartTrivyContainerInternal(ctx, dockerClient, "single-scan", config, hostConfig)
	if err != nil {
		return nil, nil, 0, 0, "", fmt.Errorf("failed to prepare trivy scan container: %w", err)
	}

	slog.DebugContext(ctx, "started trivy scan container", "containerId", containerID)
	s.setScanPhaseInternal(imageID, vulnerability.ScanPhaseScanningImage)

	logsCtx, logsCancel := context.WithCancel(ctx)
	logs, err := dockerClient.ContainerLogs(logsCtx, containerID, containertypes.LogsOptions{
		ShowStdout: true,
		ShowStderr: true,
		Follow:     true,
	})
	if err != nil {
		logsCancel()
		return nil, nil, 0, 0, "", fmt.Errorf("failed to stream trivy logs: %w", err)
	}

	var closeLogsOnce sync.Once
	closeLogs := func() {
		closeLogsOnce.Do(func() {
			logsCancel()
			if closeErr := logs.Close(); closeErr != nil && !isExpectedDockerStreamEndErrorInternal(closeErr) {
				slog.WarnContext(ctx, "failed to close trivy scan logs stream", "error", closeErr)
			}
		})
	}
	defer closeLogs()

	logDone := startDockerLogCopyInternal(logs, stdoutFile, stderrFile)

	startTime := time.Now()
	waitTimeout := trivyContainerWaitTimeoutInternal(s.getTrivyScanTimeoutArg())
	waitCtx, waitCancel := context.WithTimeout(ctx, waitTimeout)
	defer waitCancel()

	statusCode, err := s.waitForTrivyContainer(waitCtx, dockerClient, containerID)
	if err != nil {
		closeLogs()
		if logErr := waitForDockerLogCopyInternal(logDone); logErr != nil {
			slog.DebugContext(ctx, "trivy log stream ended with error while handling wait failure", "error", logErr)
		}
		return nil, nil, 0, 0, "", err
	}

	// Wait for the log copy goroutine to complete naturally. On some Docker
	// variants (e.g. Synology with Docker API 1.43), the daemon may not have
	// fully flushed container stdout before ContainerWait returns. Cancelling
	// the stream immediately after ContainerWait can truncate the JSON output
	// and cause "unexpected EOF" or empty-output decode errors.
	//
	// Strategy: wait up to logDrainDeadline for the stream to close on its own,
	// then force-close it (for Docker variants that keep the stream open after
	// container exit, e.g. older Docker builds that never send EOF).
	const logDrainDeadline = 30 * time.Second
	logDrainTimer := time.NewTimer(logDrainDeadline)
	defer logDrainTimer.Stop()

	select {
	case logErr := <-logDone:
		closeLogs() // clean up context / connection
		if logErr != nil && !isExpectedDockerStreamEndErrorInternal(logErr) {
			return nil, nil, 0, 0, "", fmt.Errorf("failed to read trivy logs: %w", logErr)
		}
	case <-logDrainTimer.C:
		// Stream did not close on its own; force-close so the goroutine exits.
		slog.DebugContext(ctx, "trivy log stream did not close after container exit; force-closing", "containerId", containerID)
		closeLogs()
		if logErr := waitForDockerLogCopyInternal(logDone); logErr != nil {
			return nil, nil, 0, 0, "", fmt.Errorf("failed to read trivy logs: %w", logErr)
		}
	}

	duration := time.Since(startTime).Milliseconds()
	success = true
	return stdoutFile, stderrFile, duration, statusCode, containerID, nil
}

func (s *VulnerabilityService) waitForTrivyContainer(
	ctx context.Context,
	dockerClient *client.Client,
	containerID string,
) (int64, error) {
	statusCh, errCh := dockerClient.ContainerWait(ctx, containerID, containertypes.WaitConditionNotRunning)

	statusCode, err := awaitContainerWaitResponseInternal(ctx, statusCh, errCh)
	if err != nil {
		if errors.Is(err, context.DeadlineExceeded) {
			return 0, fmt.Errorf("trivy container wait timed out: %w", err)
		}
		if errors.Is(err, context.Canceled) {
			return 0, fmt.Errorf("scan cancelled: %w", err)
		}
		return 0, fmt.Errorf("trivy container wait failed: %w", err)
	}

	return statusCode, nil
}

func awaitContainerWaitResponseInternal(
	ctx context.Context,
	statusCh <-chan containertypes.WaitResponse,
	errCh <-chan error,
) (int64, error) {
	for statusCh != nil || errCh != nil {
		select {
		case waitResp, ok := <-statusCh:
			if !ok {
				statusCh = nil
				continue
			}
			return waitResp.StatusCode, nil
		case err, ok := <-errCh:
			if !ok {
				errCh = nil
				continue
			}
			if err != nil {
				return 0, err
			}
		case <-ctx.Done():
			return 0, ctx.Err()
		}
	}

	return 0, errors.New("trivy container wait ended without status")
}

func (s *VulnerabilityService) runTrivyScan(ctx context.Context, trivyImage string, imageName string, imageID string) (*vulnerability.ScanResult, error) {
	slog.DebugContext(ctx,
		"running trivy scan",
		"imageId", imageID,
		"imageName", imageName,
		"trivyImage", trivyImage,
	)

	slotID, releaseSlot, err := s.acquireTrivyScanSlotInternal(ctx)
	if err != nil {
		return nil, err
	}
	defer releaseSlot()

	// Use per-image locking to allow concurrent scans of different images
	lock := s.getImageLock(imageID)
	lock.Lock()
	defer lock.Unlock()

	dockerClient, err := s.dockerService.GetClient()
	if err != nil {
		return nil, fmt.Errorf("failed to connect to Docker: %w", err)
	}

	cacheVolume, err := s.ensureTrivyCacheVolumeInternal(ctx)
	if err != nil {
		return nil, err
	}

	// Get Trivy config files if they exist
	configContent, ignoreContent, err := s.getTrivyConfigFiles()
	if err != nil {
		slog.WarnContext(ctx, "failed to get trivy config files", "error", err)
	}

	cacheDir := s.getTrivySingleScanCacheDirForSlotInternal(slotID)
	if cacheDir != "" {
		slog.DebugContext(ctx,
			"using slot-based trivy cache dir for scan",
			"slotId", slotID,
			"cacheDir", cacheDir,
			"concurrentScanContainers", s.getTrivyConcurrentScanContainersInternal(),
		)
	}

	outputPath := newTrivyOutputPathInternal()

	cmdArgs, tempFiles := s.buildTrivyCommandArgs(ctx, imageName, configContent, ignoreContent, cacheDir, outputPath)
	defer cleanupTempFiles(ctx, tempFiles)

	config := buildTrivyContainerConfig(trivyImage, cmdArgs)
	resources, cpuSet, applyLimits := s.getTrivyContainerResourceOptionsInternal(ctx, dockerClient)
	hostConfig := buildTrivyHostConfig(cacheVolume, tempFiles, resources, cpuSet, applyLimits)
	s.setScanPhaseInternal(imageID, vulnerability.ScanPhaseCreatingContainer)

	stdoutFile, stderrFile, duration, statusCode, containerID, err := s.runTrivyContainer(ctx, dockerClient, imageID, config, hostConfig)
	if err != nil {
		return nil, err
	}
	defer cleanupTrivyLogTempFilesInternal(ctx, stdoutFile, stderrFile)
	defer removeDockerContainerInternal(ctx, dockerClient, containerID, "failed to cleanup trivy scan container")

	if statusCode != 0 {
		errMsg := readTempFileExcerptInternal(stderrFile, trivyErrorExcerptSize)
		if errMsg == "" {
			errMsg = readTempFileExcerptInternal(stdoutFile, trivyErrorExcerptSize)
		}
		if errMsg == "" {
			errMsg = fmt.Sprintf("exit status %d", statusCode)
		}
		logTrivyScanFailureDiagnosticsInternal(ctx, imageName, imageID, statusCode, stdoutFile, stderrFile, "container non-zero exit")
		return nil, formatTrivyExitErrorInternal(statusCode, errMsg, imageName)
	}

	trivyOutput, outputErr := readTrivyOutputFromContainerFileInternal(ctx, dockerClient, containerID, outputPath)
	if outputErr != nil {
		slog.WarnContext(ctx,
			"failed to read trivy output file from single-scan container; falling back to stdout parsing",
			"containerId", containerID,
			"outputPath", outputPath,
			"error", outputErr,
		)
	}

	var trivyReport *vulnerability.TrivyReport
	if len(trivyOutput) > 0 {
		trivyReport, err = decodeTrivyReportFromBytesInternal(trivyOutput)
	} else {
		trivyReport, err = decodeTrivyReportFromFileInternal(stdoutFile)
	}
	if err != nil {
		if errors.Is(err, io.EOF) {
			errMsg := readTempFileExcerptInternal(stderrFile, trivyErrorExcerptSize)
			if errMsg == "" {
				errMsg = "trivy scan produced no output"
			}
			logTrivyScanFailureDiagnosticsInternal(ctx, imageName, imageID, statusCode, stdoutFile, stderrFile, "container empty output")
			return nil, fmt.Errorf("trivy scan failed: %s", errMsg)
		}

		logTrivyScanFailureDiagnosticsInternal(ctx, imageName, imageID, statusCode, stdoutFile, stderrFile, "container parse error")
		return nil, fmt.Errorf("failed to parse trivy output: %w", err)
	}

	if trivyReport == nil {
		errMsg := readTempFileExcerptInternal(stderrFile, trivyErrorExcerptSize)
		if errMsg == "" {
			errMsg = "trivy scan produced no output"
		}
		logTrivyScanFailureDiagnosticsInternal(ctx, imageName, imageID, statusCode, stdoutFile, stderrFile, "container nil report")
		return nil, fmt.Errorf("trivy scan failed: %s", errMsg)
	}

	// Convert Trivy report to our ScanResult format
	result := vulnerability.ConvertTrivyReportToScanResult(trivyReport, imageID, time.Now(), duration)
	result.ScannerVersion = s.GetTrivyVersion(ctx)
	totalVulnerabilities := 0
	if result.Summary != nil {
		totalVulnerabilities = result.Summary.Total
	}

	slog.DebugContext(ctx,
		"trivy scan finished",
		"imageId", imageID,
		"imageName", imageName,
		"durationMs", duration,
		"status", result.Status,
		"vulnerabilities", totalVulnerabilities,
	)

	return result, nil
}

func (s *VulnerabilityService) saveScanResultWithRetryInternal(
	ctx context.Context,
	result *vulnerability.ScanResult,
	maxAttempts int,
	retryDelay time.Duration,
) error {
	if maxAttempts <= 0 {
		maxAttempts = 1
	}
	if retryDelay < 0 {
		retryDelay = 0
	}

	var lastErr error
	for attempt := 1; attempt <= maxAttempts; attempt++ {
		lastErr = s.saveScanResult(ctx, result)
		if lastErr == nil {
			if attempt > 1 {
				slog.DebugContext(ctx,
					"save scan result succeeded after retry",
					"attempt", attempt,
					"maxAttempts", maxAttempts,
					"imageId", result.ImageID,
					"status", result.Status,
				)
			}
			return nil
		}

		if attempt < maxAttempts {
			if !isRetryableScanSaveErrorInternal(lastErr) {
				break
			}

			if retryDelay > 0 {
				delay := retryDelay * time.Duration(1<<(attempt-1))
				if delay > defaultScanSaveRetryMaxDelay {
					delay = defaultScanSaveRetryMaxDelay
				}

				timer := time.NewTimer(delay)
				select {
				case <-ctx.Done():
					timer.Stop()
					s.saveScanResultStatusFallbackInternal(ctx, result, ctx.Err())
					return ctx.Err()
				case <-timer.C:
				}
			}
		}
	}

	// Ensure scan status does not stay stuck as scanning when full result
	// persistence fails. Best-effort minimal status write.
	s.saveScanResultStatusFallbackInternal(ctx, result, lastErr)

	return lastErr
}

func isRetryableScanSaveErrorInternal(err error) bool {
	if err == nil {
		return false
	}

	errMsg := strings.ToLower(strings.TrimSpace(err.Error()))
	return strings.Contains(errMsg, "database is locked") ||
		strings.Contains(errMsg, "database table is locked") ||
		strings.Contains(errMsg, "database is busy") ||
		strings.Contains(errMsg, "resource busy") ||
		strings.Contains(errMsg, "timeout")
}

func (s *VulnerabilityService) saveScanResultStatusFallbackInternal(ctx context.Context, result *vulnerability.ScanResult, originalErr error) {
	if s.db == nil || result == nil || result.ImageID == "" {
		return
	}

	var summary *vulnerability.SeveritySummary
	if result.Summary != nil {
		summary = result.Summary
	} else {
		summary = &vulnerability.SeveritySummary{}
	}

	updates := map[string]any{
		"image_name":      result.ImageName,
		"status":          string(result.Status),
		"scan_time":       result.ScanTime,
		"duration":        result.Duration,
		"critical_count":  summary.Critical,
		"high_count":      summary.High,
		"medium_count":    summary.Medium,
		"low_count":       summary.Low,
		"unknown_count":   summary.Unknown,
		"total_count":     summary.Total,
		"scanner_version": result.ScannerVersion,
	}

	errMsg := strings.TrimSpace(result.Error)
	if errMsg == "" && originalErr != nil {
		errMsg = fmt.Sprintf("failed to persist full scan result: %v", originalErr)
	}
	if errMsg == "" {
		updates["error"] = nil
	} else {
		updates["error"] = errMsg
	}

	if err := s.db.WithContext(ctx).
		Model(&models.VulnerabilityScanRecord{}).
		Where("id = ?", result.ImageID).
		Updates(updates).Error; err != nil {
		slog.WarnContext(ctx,
			"failed fallback scan status persistence",
			"imageId", result.ImageID,
			"status", result.Status,
			"error", err,
			"originalError", originalErr,
		)
		return
	}

	slog.WarnContext(ctx,
		"persisted fallback scan status after full save failure",
		"imageId", result.ImageID,
		"status", result.Status,
		"originalError", originalErr,
	)
}

// saveScanResult saves the scan result to the database
func (s *VulnerabilityService) saveScanResult(ctx context.Context, result *vulnerability.ScanResult) error {
	if s.db == nil {
		return nil
	}

	s.ensureSummary(result)

	// Convert vulnerabilities to JSON
	var vulnJSON models.StringSlice
	if len(result.Vulnerabilities) > 0 {
		vulnBytes, err := json.Marshal(result.Vulnerabilities)
		if err != nil {
			return fmt.Errorf("failed to marshal vulnerabilities: %w", err)
		}
		vulnJSON = models.StringSlice{string(vulnBytes)}
	}

	var errPtr *string
	if result.Error != "" {
		errPtr = &result.Error
	}

	var summary *vulnerability.SeveritySummary
	if result.Summary != nil {
		summary = result.Summary
	} else {
		summary = &vulnerability.SeveritySummary{}
	}

	record := models.VulnerabilityScanRecord{
		ID:              result.ImageID,
		ImageName:       result.ImageName,
		Status:          string(result.Status),
		ScanTime:        result.ScanTime,
		Duration:        result.Duration,
		CriticalCount:   summary.Critical,
		HighCount:       summary.High,
		MediumCount:     summary.Medium,
		LowCount:        summary.Low,
		UnknownCount:    summary.Unknown,
		TotalCount:      summary.Total,
		Vulnerabilities: vulnJSON,
		Error:           errPtr,
		ScannerVersion:  result.ScannerVersion,
	}

	// Upsert the record
	return s.db.WithContext(ctx).Clauses(clause.OnConflict{
		Columns:   []clause.Column{{Name: "id"}},
		UpdateAll: true,
	}).Create(&record).Error
}

func (s *VulnerabilityService) fixedVulnerabilitiesForNotifications(
	ctx context.Context,
	result *vulnerability.ScanResult,
) []vulnerability.Vulnerability {
	if result == nil || result.Status != vulnerability.ScanStatusCompleted || len(result.Vulnerabilities) == 0 {
		return nil
	}

	vulnerabilities := result.Vulnerabilities
	filtered, err := s.filterIgnoredVulnerabilitiesForImage(ctx, result.ImageID, vulnerabilities)
	if err != nil {
		slog.WarnContext(ctx, "failed to filter ignored vulnerabilities for notifications", "error", err)
	} else {
		vulnerabilities = filtered
	}

	fixable := make([]vulnerability.Vulnerability, 0, len(vulnerabilities))
	for i := range vulnerabilities {
		v := vulnerabilities[i]
		if strings.TrimSpace(v.FixedVersion) == "" {
			continue
		}
		fixable = append(fixable, v)
	}

	return fixable
}

func (s *VulnerabilityService) filterIgnoredVulnerabilitiesForImage(
	ctx context.Context,
	imageID string,
	vulns []vulnerability.Vulnerability,
) ([]vulnerability.Vulnerability, error) {
	if s.db == nil || len(vulns) == 0 || imageID == "" {
		return vulns, nil
	}

	var ignores []models.VulnerabilityIgnore
	if err := s.db.WithContext(ctx).Where("image_id = ?", imageID).Find(&ignores).Error; err != nil {
		return nil, err
	}
	if len(ignores) == 0 {
		return vulns, nil
	}

	ignoredKeys := make(map[string]struct{}, len(ignores))
	for _, ignore := range ignores {
		key := fmt.Sprintf("%s:%s:%s:%s", ignore.ImageID, ignore.VulnerabilityID, ignore.PkgName, ignore.InstalledVersion)
		ignoredKeys[key] = struct{}{}
	}

	filtered := make([]vulnerability.Vulnerability, 0, len(vulns))
	for _, vuln := range vulns {
		key := fmt.Sprintf("%s:%s:%s:%s", imageID, vuln.VulnerabilityID, vuln.PkgName, vuln.InstalledVersion)
		if _, isIgnored := ignoredKeys[key]; isIgnored {
			continue
		}
		filtered = append(filtered, vuln)
	}

	return filtered, nil
}

// convertRecordToResult converts a database record to a ScanResult
func (s *VulnerabilityService) convertRecordToResult(record *models.VulnerabilityScanRecord) (*vulnerability.ScanResult, error) {
	result := &vulnerability.ScanResult{
		ImageID:   record.ID,
		ImageName: record.ImageName,
		ScanTime:  record.ScanTime,
		Status:    vulnerability.ScanStatus(record.Status),
		Duration:  record.Duration,
		Summary: &vulnerability.SeveritySummary{
			Critical: record.CriticalCount,
			High:     record.HighCount,
			Medium:   record.MediumCount,
			Low:      record.LowCount,
			Unknown:  record.UnknownCount,
			Total:    record.TotalCount,
		},
		ScannerVersion: record.ScannerVersion,
	}

	if record.Error != nil {
		result.Error = *record.Error
	}

	// Parse vulnerabilities from JSON
	if len(record.Vulnerabilities) > 0 && record.Vulnerabilities[0] != "" {
		var vulns []vulnerability.Vulnerability
		if err := json.Unmarshal([]byte(record.Vulnerabilities[0]), &vulns); err != nil {
			slog.Warn("failed to unmarshal vulnerabilities", "error", err)
		} else {
			result.Vulnerabilities = vulns
		}
	}

	s.ensureSummary(result)
	s.applyScanPhaseToResultInternal(result)

	return result, nil
}

func (s *VulnerabilityService) ensureSummary(result *vulnerability.ScanResult) {
	if result == nil {
		return
	}

	if len(result.Vulnerabilities) == 0 {
		if result.Summary == nil {
			result.Summary = &vulnerability.SeveritySummary{}
		}
		return
	}

	if result.Summary != nil && result.Summary.Total > 0 {
		return
	}

	result.Summary = buildSeveritySummaryFromVulnerabilitiesInternal(result.Vulnerabilities)
}

func buildSeveritySummaryFromVulnerabilitiesInternal(vulns []vulnerability.Vulnerability) *vulnerability.SeveritySummary {
	summary := &vulnerability.SeveritySummary{}
	for _, vuln := range vulns {
		switch vuln.Severity {
		case vulnerability.SeverityCritical:
			summary.Critical++
		case vulnerability.SeverityHigh:
			summary.High++
		case vulnerability.SeverityMedium:
			summary.Medium++
		case vulnerability.SeverityLow:
			summary.Low++
		case vulnerability.SeverityUnknown:
			summary.Unknown++
		default:
			summary.Unknown++
		}
		summary.Total++
	}
	return summary
}

// logScanEvent logs a vulnerability scan event
func (s *VulnerabilityService) logScanEvent(ctx context.Context, envID string, imageID, imageName string, user models.User, success bool, errMsg string) {
	metadata := models.JSON{
		"action":    "vulnerability_scan",
		"imageId":   imageID,
		"imageName": imageName,
		"success":   success,
	}
	if errMsg != "" {
		metadata["error"] = errMsg
	}

	environmentID := envID
	if environmentID == "" {
		environmentID = "0"
	}

	eventType := models.EventTypeImageScan
	if err := s.eventService.LogImageEvent(ctx, eventType, imageID, imageName, user.ID, user.Username, environmentID, metadata); err != nil {
		slog.WarnContext(ctx, "failed to log vulnerability scan event", "error", err)
	}
}

// logScheduledScanEvent logs a vulnerability scan event using the dedicated scheduled scan event type.
func (s *VulnerabilityService) logScheduledScanEvent(ctx context.Context, envID string, imageID, imageName string, user models.User, success bool, errMsg string) {
	metadata := models.JSON{
		"action":    "scheduled_vulnerability_scan",
		"imageId":   imageID,
		"imageName": imageName,
		"success":   success,
	}
	if errMsg != "" {
		metadata["error"] = errMsg
	}

	environmentID := envID
	if environmentID == "" {
		environmentID = "0"
	}

	if err := s.eventService.LogImageEvent(ctx, models.EventTypeImageVulnerabilityScan, imageID, imageName, user.ID, user.Username, environmentID, metadata); err != nil {
		slog.WarnContext(ctx, "failed to log scheduled vulnerability scan event", "error", err)
	}
}

// stringPtrValueOrEmptyInternal returns the string value from a pointer or empty string if nil
func stringPtrValueOrEmptyInternal(p *string) string {
	if p == nil {
		return ""
	}
	return *p
}

// IgnoreVulnerability creates a new ignore record for a vulnerability
func (s *VulnerabilityService) IgnoreVulnerability(ctx context.Context, envID string, payload *vulnerability.IgnorePayload) (*models.VulnerabilityIgnore, error) {
	if s.db == nil {
		return nil, errors.New("database not available")
	}

	// Check if already ignored (composite key check)
	var existing models.VulnerabilityIgnore
	err := s.db.WithContext(ctx).Where(
		"environment_id = ? AND image_id = ? AND vulnerability_id = ? AND pkg_name = ? AND installed_version = ?",
		envID, payload.ImageID, payload.VulnerabilityID, payload.PkgName, payload.InstalledVersion,
	).First(&existing).Error

	if err == nil {
		return nil, errors.New("vulnerability is already ignored")
	}

	if !errors.Is(err, gorm.ErrRecordNotFound) {
		return nil, fmt.Errorf("failed to check existing ignore: %w", err)
	}

	ignore := &models.VulnerabilityIgnore{
		EnvironmentID:    envID,
		ImageID:          payload.ImageID,
		VulnerabilityID:  payload.VulnerabilityID,
		PkgName:          payload.PkgName,
		InstalledVersion: payload.InstalledVersion,
		Reason:           payload.Reason,
		CreatedBy:        payload.CreatedBy,
	}

	if err := s.db.WithContext(ctx).Create(ignore).Error; err != nil {
		return nil, fmt.Errorf("failed to create ignore record: %w", err)
	}

	slog.InfoContext(ctx, "vulnerability ignored",
		"vulnerability_id", payload.VulnerabilityID,
		"image_id", payload.ImageID,
		"pkg_name", payload.PkgName,
	)

	return ignore, nil
}

// UnignoreVulnerability removes an ignore record
func (s *VulnerabilityService) UnignoreVulnerability(ctx context.Context, envID string, ignoreID string) error {
	if s.db == nil {
		return errors.New("database not available")
	}

	result := s.db.WithContext(ctx).Where("id = ? AND environment_id = ?", ignoreID, envID).Delete(&models.VulnerabilityIgnore{})
	if result.Error != nil {
		return fmt.Errorf("failed to delete ignore record: %w", result.Error)
	}

	if result.RowsAffected == 0 {
		return errors.New("ignore record not found")
	}

	slog.InfoContext(ctx, "vulnerability unignored", "ignore_id", ignoreID)
	return nil
}

func applyIgnoredVulnerabilitiesSort(query *gorm.DB, sort string) *gorm.DB {
	if sort == "" {
		return query.Order("created_at DESC")
	}

	for part := range strings.SplitSeq(sort, ",") {
		part = strings.TrimSpace(part)
		if part == "" {
			continue
		}

		desc := false
		switch {
		case strings.HasPrefix(part, "-"):
			desc = true
			part = strings.TrimPrefix(part, "-")
		case strings.HasPrefix(part, "+"):
			part = strings.TrimPrefix(part, "+")
		}

		query = applyIgnoredVulnerabilitiesSortPart(query, part, desc)
	}

	return query
}

func applyIgnoredVulnerabilitiesSortPart(query *gorm.DB, part string, desc bool) *gorm.DB {
	direction := "ASC"
	if desc {
		direction = "DESC"
	}

	switch part {
	case "createdAt":
		return query.Order("created_at " + direction)
	case "vulnerabilityId":
		return query.Order("vulnerability_id " + direction)
	default:
		return query.Order("created_at DESC")
	}
}

func mapIgnoredVulnerabilities(ignores []models.VulnerabilityIgnore) []vulnerability.IgnoredVulnerability {
	result := make([]vulnerability.IgnoredVulnerability, len(ignores))
	for i, ignore := range ignores {
		result[i] = vulnerability.IgnoredVulnerability{
			ID:               ignore.ID,
			EnvironmentID:    ignore.EnvironmentID,
			ImageID:          ignore.ImageID,
			VulnerabilityID:  ignore.VulnerabilityID,
			PkgName:          ignore.PkgName,
			InstalledVersion: ignore.InstalledVersion,
			Reason:           ignore.Reason,
			CreatedBy:        ignore.CreatedBy,
			CreatedAt:        ignore.CreatedAt,
		}
	}
	return result
}

func buildIgnoredVulnerabilitiesResponse(total int64, params pagination.QueryParams, ignores []models.VulnerabilityIgnore) pagination.Response {
	filtered := pagination.FilterResult[models.VulnerabilityIgnore]{
		Items:          ignores,
		TotalCount:     total,
		TotalAvailable: total,
	}
	return pagination.BuildResponseFromFilterResult(filtered, params)
}

// ListIgnoredVulnerabilities returns a list of ignored vulnerabilities for an environment
func (s *VulnerabilityService) ListIgnoredVulnerabilities(ctx context.Context, envID string, params pagination.QueryParams) ([]vulnerability.IgnoredVulnerability, pagination.Response, error) {
	if params.Limit == 0 {
		params.Limit = 20
	}

	if s.db == nil {
		return []vulnerability.IgnoredVulnerability{}, pagination.Response{
			TotalPages:      1,
			TotalItems:      0,
			CurrentPage:     1,
			ItemsPerPage:    params.Limit,
			GrandTotalItems: 0,
		}, nil
	}

	var ignores []models.VulnerabilityIgnore
	query := s.db.WithContext(ctx).Where("environment_id = ?", envID)
	query = applyIgnoredVulnerabilitiesSort(query, params.Sort)

	// Count total
	var total int64
	if err := query.Model(&models.VulnerabilityIgnore{}).Count(&total).Error; err != nil {
		return nil, pagination.Response{}, fmt.Errorf("failed to count ignored vulnerabilities: %w", err)
	}

	// Apply pagination
	offset := params.Start
	if err := query.Offset(offset).Limit(params.Limit).Find(&ignores).Error; err != nil {
		return nil, pagination.Response{}, fmt.Errorf("failed to list ignored vulnerabilities: %w", err)
	}

	result := mapIgnoredVulnerabilities(ignores)
	response := buildIgnoredVulnerabilitiesResponse(total, params, ignores)

	return result, response, nil
}

// GetIgnoreRecordsForImage retrieves all ignore records for a specific image
func (s *VulnerabilityService) GetIgnoreRecordsForImage(ctx context.Context, envID string, imageID string) ([]models.VulnerabilityIgnore, error) {
	if s.db == nil {
		return nil, nil
	}

	var ignores []models.VulnerabilityIgnore
	if err := s.db.WithContext(ctx).Where("environment_id = ? AND image_id = ?", envID, imageID).Find(&ignores).Error; err != nil {
		return nil, fmt.Errorf("failed to get ignore records: %w", err)
	}

	return ignores, nil
}

// filterIgnoredVulnerabilities removes ignored vulnerabilities from the list
func (s *VulnerabilityService) filterIgnoredVulnerabilities(ctx context.Context, envID string, vulns []vulnerability.VulnerabilityWithImage) ([]vulnerability.VulnerabilityWithImage, error) {
	if s.db == nil || len(vulns) == 0 {
		return vulns, nil
	}

	// Get all ignore records for this environment
	var ignores []models.VulnerabilityIgnore
	if err := s.db.WithContext(ctx).Where("environment_id = ?", envID).Find(&ignores).Error; err != nil {
		return nil, fmt.Errorf("failed to get ignore records: %w", err)
	}

	if len(ignores) == 0 {
		return vulns, nil
	}

	// Build a set of ignored vulnerability keys
	ignoredKeys := make(map[string]struct{}, len(ignores))
	for _, ignore := range ignores {
		key := fmt.Sprintf("%s:%s:%s:%s", ignore.ImageID, ignore.VulnerabilityID, ignore.PkgName, ignore.InstalledVersion)
		ignoredKeys[key] = struct{}{}
	}

	// Filter out ignored vulnerabilities
	filtered := make([]vulnerability.VulnerabilityWithImage, 0, len(vulns))
	for _, vuln := range vulns {
		key := fmt.Sprintf("%s:%s:%s:%s", vuln.ImageID, vuln.VulnerabilityID, vuln.PkgName, vuln.InstalledVersion)
		if _, isIgnored := ignoredKeys[key]; !isIgnored {
			filtered = append(filtered, vuln)
		}
	}

	return filtered, nil
}
